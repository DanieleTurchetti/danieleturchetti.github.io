[["index.html", "1 Welcome to multilevel modelling", " 1 Welcome to multilevel modelling This website contains all the worksheets of labs for Multilevel Modeling in 2024/25. "],["multilevel-modelling-practical-1-week-2.html", "2 Multilevel Modelling Practical 1 (Week 2) 2.1 Instructions – start here! 2.2 Exercises 1 2.3 Exercises 2", " 2 Multilevel Modelling Practical 1 (Week 2) 2.1 Instructions – start here! The first part of this notebook (Exercise 1) takes you through a simple linear regression (using simulated data). The second part of the notebook (Exercise 2) involves a multiple linear regression analysis of hourly wage data. 2.2 Exercises 1 Copy and paste the following code chunk which generates pairs \\((x_1,y_1), (x_2,y_2),\\ldots,(x_n,y_n)\\) where \\(n=200\\). set.seed(43515) # for reproducibility n &lt;- 200 x &lt;- rnorm(n) y &lt;- 2+3*x+rnorm(n,0,1) We can visualise the data with a scatterplot: plot(x,y,main=&quot;Scatterplot&quot;) What distribution are the \\(x\\) and \\(y\\) values simulated from? Do histograms of \\(x\\) and \\(y\\) values match your answer? Click for solution Let \\(X\\) and \\(Y\\) be the random variables that the \\(x\\) and \\(y\\) values are simulations of (respectively). We have that \\(X\\sim N(0,1)\\) and \\(Y|X=x \\sim N(2+3x,1)\\). Hence \\(Y\\sim N(2,3^2+1^2)\\equiv N(2,10)\\). par(mfrow=c(1,2)) hist(x,freq=FALSE) hist(y,freq=FALSE) Histograms are symmetric about 0 and 2, with most values between \\(-3\\) and \\(+3\\) (mean plus/minus 3 standard deviations) for \\(x\\), and between \\(-7\\) and \\(+11\\) for \\(y\\) (mean plus/minus roughly 3 standard deviations). Calculate the Pearson correlation coefficient. How does this compare to the theoretical correlation? (Hint: recall that \\(Cov(X,a+bX)=Cov(X,a)+Cov(X,bX)=bCov(X,X)=bVar(X)\\) for constants \\(a\\) and \\(b\\).) Click for solution (r.pearson &lt;- cor(x,y)) ## [1] 0.9310128 The theoretical covariance is \\(Cov(X,Y)=Cov(X,2+3X)=3Var(X)=3\\). Hence, the theoretical correlation between \\(X\\) and \\(Y\\) is \\(3/\\sqrt{Var(X)Var(Y)}=3/ \\sqrt{10}=0.95\\). We can fit a linear regression model to these data and summarise the output via model &lt;- lm(y~x) summary(model) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.6323 -0.6375 -0.0632 0.6329 2.9024 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.99094 0.07455 26.71 &lt;2e-16 *** ## x 2.92914 0.08161 35.89 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.054 on 198 degrees of freedom ## Multiple R-squared: 0.8668, Adjusted R-squared: 0.8661 ## F-statistic: 1288 on 1 and 198 DF, p-value: &lt; 2.2e-16 Interpret this output. (At least three comments expected here!) Click for solution The estimates of the intercept \\(b_0\\) and slope \\(b_1\\) are in agreement with the ground truth values that generated the data (\\(\\beta_0=2\\), \\(\\beta_1=3\\)). Unsurprisingly, the t-test of the null hypothesis that \\(H_0:\\beta_1=0\\) suggests strong evidence against the null: it appears that the slope is needed. The F-test gives the same conclusion. The coefficient of determination is \\(R^2=0.8668\\) suggesting that almost 90% of the variation in \\(Y\\) is being explained by the regression on \\(x\\). Note that (r.pearson^2) ## [1] 0.8667848 gives \\(R^2\\). Reproduce the scatterplot and overlay the regression line. (Hint: recall the abline() function and note that coef(model) gives the estimated intercept and slope.) Click for solution plot(x,y) abline(coef(model)) In what follows, it will be helpful to work with sorted (in increasing order) values of \\(x\\) and the associated values of \\(y\\). Hence execute the following code (and try to understand it): ind &lt;- sort(x,index.return=TRUE) x &lt;- x[ind$ix] y &lt;- y[ind$ix] model &lt;- lm(y~x) Recall that the predict() function can be used to generate fitted values \\(\\hat{y}_i\\), confidence and prediction intervals. The following code generates fitted values and the lower / upper limits of a 95% confidence interval for the mean response \\(\\beta_0+\\beta_1 x_i\\): fit.y &lt;- predict(model,newdata = data.frame(x),interval = &quot;confidence&quot;) head(fit.y) #inspect first few rows ## fit lwr upr ## 1 -4.607650 -5.003545 -4.211755 ## 2 -4.527100 -4.918888 -4.135311 ## 3 -4.161157 -4.534383 -3.787930 ## 4 -3.768590 -4.122093 -3.415088 ## 5 -3.516371 -3.857319 -3.175424 ## 6 -3.055568 -3.373856 -2.737279 Overlay (in red) on your plot from part 4 the 95% confidence interval for the expected response \\(\\beta_0+\\beta_1 x_i\\) for each \\(x_i\\). (Hint: lines() will be useful here.) Click for solution plot(x,y) abline(coef(model)) lines(x,fit.y[,2],type=&quot;l&quot;,col=&quot;red&quot;) lines(x,fit.y[,3],type=&quot;l&quot;,col=&quot;red&quot;) By using the predict() function with interval = \"prediction\", overlay (in green) on your plot from part 5 the 95% prediction interval for each \\(y_i\\). Comment. Click for solution fit.yp &lt;- predict(model,newdata = data.frame(x),interval = &quot;prediction&quot;) plot(x,y) abline(coef(model)) lines(x,fit.y[,2],type=&quot;l&quot;,col=&quot;red&quot;) lines(x,fit.y[,3],type=&quot;l&quot;,col=&quot;red&quot;) lines(x,fit.yp[,2],type=&quot;l&quot;,col=&quot;green&quot;) lines(x,fit.yp[,3],type=&quot;l&quot;,col=&quot;green&quot;) The prediction interval is wider than the confidence interval, as expected (recall that the prediction interval takes into account the variance of the error term). Check the regression assumptions of model. Click for solution plot(model) The Q-Q plots suggests that the normality assumption is reasonable. Plots of the residuals against fitted values show no obvious pattern (i.e. no fanning out; the constant variance assumption appears reasonable, and no systematic shape; the linear relationship between response and predictors appears reasonable). The last plot indicates some outliers but these do not appear to be of high leverage (according to Cook’s distance) so it is not necessary to remove them. All of these comments are as expected since we’ve simulated the data from a simpler linear regression model so we’d be surprised if it didn’t fit well! Let’s add an outlying data point to our synthetic data set and look at the resulting scatter plot: x &lt;- c(x,0) y &lt;- c(y, 15) plot(x,y,main=&quot;Scatter plot with outlier&quot;) Fit the simple regression model again (call it model_out1) and check the assumptions. What do you notice? Click for solution model_out1 &lt;- lm(y~x) plot(model_out1) The assumptions look reasonable. The outlier is not influential (Cook’s distance is less than 1 for the outlier). In fact, we can see that the outlier appears to have almost no affect on the line of best fit, whether it’s included or not. plot(x,y) abline(coef(model_out1)) abline(coef(model),col=2) #least squares line without the outlier Let’s add another outlying data point to our synthetic data set and look at the resulting scatter plot: x &lt;- c(x,3) y &lt;- c(y, 30) plot(x,y,main=&quot;Scatter plot with two outliers&quot;) Fit the simple regression model again (call it model_out2) and check the assumptions. What do you notice? Click for solution model_out2 &lt;- lm(y~x) plot(model_out2) The second outlier has high leverage (Cook’s distance greater than 1). In fact, you can see the effect of including it in the data set via: plot(x,y) abline(coef(model_out2)) abline(coef(model),col=2) #least squares line without the outlier The line of best fit obtained with the (second) outlier included in the data, has a larger slope coefficient than that obtained without the (second) outlier. 2.3 Exercises 2 This exercise concerns the data set hwages consisting of 534 observations on 7 variables. We will focus on the following variables: wages - hourly wage (in dollars). We will treat this as the response. workexp - work experience in years. education - schooling in years. sector - 0 for private and 1 for public (e.g. hospital, school etc). Read in the data from Andy’s Github page with hwages &lt;- read.csv(file=&quot;https://andygolightly.github.io/teaching/MATH43515/hwages.csv&quot;) Let’s also explicitly store the columns we will need as separate variables: data &lt;- hwages wages &lt;- data$wages #response / dependent variable workexp &lt;- data$workexp educ &lt;- data$education sector &lt;- as.factor(data$sector) Plot a histogram of the dependent variable (wages). Do you see any skewness? Is this a problem? Click for solution hist(wages,main=&quot;Histogram of wages (dollars per hour)&quot;) Indeed there is some skewness although this is not necessarily a problem. A skewed dependent variable does not violate any assumptions since we require normality of residuals, not variables. Let’s transform the response variable via the natural logarithm: lwages &lt;- log(wages) How does a histogram of lwages compare to that in part 1? Click for solution par(mfrow=c(1,2)) hist(wages,main=&quot;wages&quot;) hist(lwages,main=&quot;ln wages&quot;) The right skew appears to be alleviated by the transformation. Denote by \\(y_i\\) the value of the log wage for person \\(i\\). Fit the model \\[ Y_i = \\beta_0 + \\beta_1 \\textrm{education}_i + \\beta_2 \\textrm{sector}_i + \\epsilon_i, \\quad i=1,\\ldots,n \\] with the result stored in model1. What do the results suggest for the predicted public sector hourly wage vs private? Hint: use lm() and summary(). Be careful with the interpretation - recall that the response is the natural logarithm of hourly wage. Click for solution model1 &lt;- lm(lwages~educ+sector) summary(model1) ## ## Call: ## lm(formula = lwages ~ educ + sector) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.08737 -0.35123 0.03087 0.33134 1.78649 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.165192 0.106130 10.979 &lt;2e-16 *** ## educ 0.076848 0.007867 9.768 &lt;2e-16 *** ## sector1 -0.232067 0.041254 -5.625 3e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.475 on 531 degrees of freedom ## Multiple R-squared: 0.1928, Adjusted R-squared: 0.1898 ## F-statistic: 63.42 on 2 and 531 DF, p-value: &lt; 2.2e-16 We see that the estimate of the variable sector is \\(-0.232\\). Hence, with the educ variable held constant, the model suggests that average hourly log wages are reduced by \\(-0.232\\) for public sector workers. Hence, actual average hourly wage is reduced by a (multiplicative) factor of \\((1-\\exp(-0.232))\\times 100=20\\%\\). We can set up functions to evaluate the equations of the two lines (one for sector=0 and one for sector=1) as functions of the variable educ as follows: eq1 &lt;- function(educ){coef(model1)[1]+coef(model1)[2]*educ} #private sector eq2 &lt;- function(educ){coef(model1)[1]+coef(model1)[2]*educ+coef(model1)[3]} #public sector Overlay the fitted line by sector type on the scatterplot of lwages against educ. (Hint: first set up a vector of x values, e.g. using seq(), against which to plot the output of eq1 and eq2.) Click for solution x &lt;- seq(min(educ),max(educ),0.1) #set up educ values at which to evaluate line plot(educ,lwages) lines(x,eq1(x),type=&quot;l&quot;,col=&quot;red&quot;) #private lines(x,eq2(x),type=&quot;l&quot;,col=&quot;green&quot;) #public As expected, the lines have the same slope but the line for sector=1 is shifted by the amount \\(b_3=-0.232\\). Add the variable named workexp to model1 (that is, fit the multiple linear regression model with this additional predictor variable). Name the resulting model model2. Click for solution model2 &lt;- lm(lwages~educ+sector+workexp) Interpret the coefficients of model2 in the context of both wage and log wage. Click for solution summary(model2) ## ## Call: ## lm(formula = lwages ~ educ + sector + workexp) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.15504 -0.30764 0.00708 0.30955 1.99176 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.674929 0.120510 5.601 3.43e-08 *** ## educ 0.098006 0.008009 12.237 &lt; 2e-16 *** ## sector1 -0.255947 0.039409 -6.495 1.92e-10 *** ## workexp 0.012668 0.001697 7.466 3.42e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4523 on 530 degrees of freedom ## Multiple R-squared: 0.2696, Adjusted R-squared: 0.2655 ## F-statistic: 65.22 on 3 and 530 DF, p-value: &lt; 2.2e-16 We have that \\(b_1=0.098\\), \\(b_2=-0.256\\) and \\(b_3=0.013\\). Hence, an additional year of schooling increases average log wage by 0.098 (with the other variables held constant). An additional year of work experience increases log wage by 0.013. The average hourly log wage for public sector workers appears to be 0.256 (log dollars) lower than for private sector workers. Working with log wages makes interpretation difficult. A better interpretation here is to look at the percentage increase or decrease resulting from a unit change in one variable (while keeping the others constant). For example, the percentage increase in average wage resulting from an additional year of schooling is \\((\\exp(0.098)-1)\\times 100=10\\%\\) (with the other variables held constant). What does the adjusted \\(R^2\\) suggest about model2 compared to model1? Click for solution The adjusted R-squared is 0.2655 for model2 versus 0.1898 for model1 suggesting a reasonable improvement in explained variation when moving to model2. These values are quite small though; only \\(27\\%\\) of the variation in the response is explained by the regression on educ, sector and workexp is not great from a performance perspective! Run the command anova(model1, model2). Which model (model1 or model2) is preferred? Click for solution anova(model1, model2) ## Analysis of Variance Table ## ## Model 1: lwages ~ educ + sector ## Model 2: lwages ~ educ + sector + workexp ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 531 119.83 ## 2 530 108.42 1 11.403 55.743 3.417e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We see that the test statistic is large (much bigger than 1) and the p-value is very small (certainly much smaller than 5%) suggesting strong evidence against the null hypothesis that the larger model offers no improvement in fit compared to the simpler model. The conclusion is that the additional workexp variable is needed. Check the regression assumptions of model2. Click for solution plot(model2) The Q-Q plots suggests that the normality assumption is reasonable. Plots of the residuals against fitted values show no obvious pattern (i.e. no fanning out; the constant variance assumption appears reasonable, and no systematic shape; the linear relationship between log wages and predictors appears reasonable). The last plot indicates some outliers but these do not appear to be of high leverage (according to Cook’s distance) so it is not necessary to remove them. End of lab! "],["multilevel-modelling-practical-2-week-3.html", "3 Multilevel Modelling Practical 2 (Week 3) 3.1 Instructions – start here! 3.2 Exercises 1 3.3 Exercise 2 3.4 Exercise 3 (if time)", " 3 Multilevel Modelling Practical 2 (Week 3) 3.1 Instructions – start here! The first part of this notebook (Exercise 1) reproduces the images displayed through the use of ggplot in Lecture 3 of this module. The code in this example is influenced by https://www.rensvandeschoot.com/tutorials/lme4/. The second part of the notebook (Exercise 2) allows you to test your ggplot2 skills. If time permits, you may apply ggplot2 more freely onto another data set (Exercise 3). We initially load two useful R packages (haven, ggplot2). #You may need to install these packages! require(haven) # to load the SPSS .sav file require(ggplot2) # used for production of graphs If you don’t have the above packages, you will need to use the usual install.packages() and library() for both. 3.2 Exercises 1 3.2.1 Acquire and prepare data Use the code below to reproduce the images from the lecture. Please do not just click your way through: try to understand and appreciate what the code does in all instances, and try to execute minor modifications of the code to observe the effect. The following command is reading the data in directly from Andy’s Github page. pop.rawdata &lt;- read_sav(file=&quot;https://andygolightly.github.io/teaching/MATH43515/popular2.sav&quot;) \\(~\\) We extract the relevant columns, relabel accordingly, and display the first six rows. pop.data &lt;- pop.rawdata[,c(&quot;pupil&quot;, &quot;class&quot;, &quot;extrav&quot;, &quot;sex&quot;, &quot;texp&quot;, &quot;popular&quot;)] colnames(pop.data)&lt;- c(&quot;pupil&quot;, &quot;class&quot;, &quot;extraversion&quot;, &quot;gender&quot;, &quot;experience&quot;, &quot;popularity&quot;) head(pop.data) # we have a look at the first 6 observations ## # A tibble: 6 × 6 ## pupil class extraversion gender experience popularity ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 5 1 [girl] 24 6.3 ## 2 2 1 7 0 [boy] 24 4.9 ## 3 3 1 4 1 [girl] 24 5.3 ## 4 4 1 3 1 [girl] 24 4.7 ## 5 5 1 5 1 [girl] 24 6 ## 6 6 1 4 0 [boy] 24 4.7 The following creates some auxiliary data frames, purely for visualization purpopses. Ex &lt;- data.frame(table(pop.data$extraversion)) colnames(Ex) &lt;- c(&quot;extraversion&quot;, &quot;frequency&quot;) Gen &lt;- data.frame(table(pop.data$gender)) colnames(Gen) &lt;- c(&quot;gender&quot;, &quot;frequency&quot;) Tex &lt;- data.frame(table(pop.data$experience)) colnames(Tex) &lt;- c(&quot;experience&quot;, &quot;frequency&quot;) 3.2.2 Exploratory analysis Produce a histogram of the response variable. ggplot(data=pop.data, aes(popularity)) + geom_histogram(bins=15) TASK: Try col=\"black\", fill=\"light blue\" inside geom_histogram(). \\(~\\) Visualise the explanatory variables as follows. ggplot(data=Ex, aes(x=extraversion, y=frequency)) + geom_bar(stat=&quot;identity&quot;) ggplot(data=Gen, aes(x=gender, y=frequency)) + geom_bar(stat=&quot;identity&quot;) ggplot(data=Tex, aes(x=experience, y=frequency)) + geom_bar(stat=&quot;identity&quot;) TASK: What does stat=\"identity\" do? Check the help file via ?geom_bar. \\(~\\) Scatterplot of popularity against extraversion and Pearson correlation: ggplot(data = pop.data, aes(x = extraversion, y = popularity)) + geom_point(size = 1.2,alpha = .8) cor(pop.data$extraversion, pop.data$popularity) ## [1] 0.3157935 TASK: What does size and alpha do in geom_point()? \\(~\\) Scatterplot of popularity against gender and Pearson correlation: ggplot(data = pop.data, aes(x = gender, y = popularity, group=gender)) + geom_boxplot() cor(pop.data$gender, pop.data$popularity) ## [1] 0.5682754 ggplot(data = pop.data, aes(x = extraversion, y = popularity, colour = as.factor(gender)) ) + geom_point(size = 1, alpha = .7, position = &quot;jitter&quot;) Let’s calculate the mean popularity and mean teacher experience score within each class and store in a data frame. Although no actual averaging takes place when calculating the teacher experience means, the code is useful for the extraction of the class level variable. pop.means &lt;- tapply(pop.data$popularity, pop.data$class, mean) # average popularity per class exp.means &lt;- tapply(pop.data$experience, pop.data$class, mean) # extracting the upper-level variable teaching experience # (no actual averaging takes place here, as experience is constant within classes) class.level&lt;- data.frame(pop.means=pop.means, exp.means=exp.means) # Plot mean popularity per class against teacher experience ggplot(data = class.level, aes(x=exp.means, y= pop.means)) + geom_point(size=2) + labs(y=&quot;mean popularity per class&quot;) + labs(x=&quot;teacher experience&quot;) Task: make clear to yourself the use of tapply() here. \\(~\\) 3.2.3 Naive simple linear regression models Let’s fit a single regression model to all data. The model takes the form \\[ y_{ij}=a + b x_{ij}+ \\epsilon_{ij}, \\quad \\epsilon_{ij}\\sim N(0,\\sigma^2), \\quad i=1,\\ldots,n_j,\\quad j=1,\\ldots,100. \\] We fit the model and extract estimates of \\(a\\) and \\(b\\) as follows. simple.linear.model&lt;- lm(popularity ~ extraversion, data=pop.data) summary(simple.linear.model)$coef ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.2728356 0.12473523 26.23826 1.237371e-130 ## extraversion 0.3458513 0.02324748 14.87694 1.481801e-47 a &lt;- simple.linear.model$coef[1] b &lt;- simple.linear.model$coef[2] Plot the data and overlay the fitted regression line: ggplot(data = pop.data, aes(x = extraversion, y = popularity)) + geom_point(size=0.7)+ geom_smooth(method = lm, # to add regression line se = TRUE, col = &quot;red&quot;, size = 1, alpha = .8) ## `geom_smooth()` using formula = &#39;y ~ x&#39; Let’s produce a scatterplot with jitter, colour by class: ggplot(data = pop.data, aes(x = extraversion, y = popularity, col=class)) + geom_jitter(size=0.8) + # to add some random noise for plotting purposes scale_color_gradientn(colours = rainbow(100)) #+ Does one line fit all? We now fit a separate model for each class. The models take the form (for each class \\(j\\)) \\[ y_{ij}=a_j+b_j x_{ij}+\\epsilon_{ij}, \\quad \\epsilon_{ij}\\sim N(0,\\sigma^2_j). \\] ggplot(data = pop.data, aes(x = extraversion,y = popularity, colour = class, group = class) ) + geom_jitter(size=0.8) + geom_smooth(method = lm, se = FALSE, size = .5, alpha = .8) + scale_color_gradientn(colours = rainbow(100)) We can extract the estimates of \\(a_j\\) and \\(b_j\\) via a for loop: fit.all &lt;- matrix(NA, 100,2) #one row for each class, cols are a and b for (j in 1:100){ #loop over classes fit.all[j,]&lt;-lm(popularity~extraversion, data=pop.data, subset=pop.data$class==j)$coef } colnames(fit.all) &lt;- c(&quot;intercept&quot;, &quot;slope&quot;) fit.all &lt;- as.data.frame(fit.all) Finally, plot histograms of the \\(a_j\\) and \\(b_j\\) estimates: ggplot(data=fit.all, aes(intercept)) + geom_histogram(bins=15) + geom_vline(xintercept=a, linetype=&quot;dashed&quot;, color = &quot;red&quot;) ggplot(data=fit.all, aes(slope)) + geom_histogram(bins=15) + geom_vline(xintercept=b, linetype=&quot;dashed&quot;, color = &quot;red&quot;) TASK (harder): suppose that we model the intercepts via \\(a_j = a +u_{j}\\) where \\(u_j\\sim N(0,\\sigma^2_u)\\) independently of all other random variables. Write down the resulting model in the form \\(y_{ij}= \\ldots\\). Is this likely to be a sensible model? What exploratory techniques can we use to answer his question? Discuss with colleagues and/or Andy. For two pupils in the same class, what is the covariance between response values? What is the covariance between the response values of two pupils from different classes? How might we model the \\(b_j\\)? (Don’t worry if this looks a bit odd - we will unpack in next week’s lecture!) \\(~\\) 3.3 Exercise 2 Load the mpg data in the ggplot2 package to obtain a data set on fuel efficiency. data(&quot;mpg&quot;, package = &quot;ggplot2&quot;) Look at the help file to see the variables available (note: ?ggplot2::mpg). You’ll need to map the plots requested below to the correct variable from the documentation. Produce a scatter plot of the fuel efficiency on a highway (motorway, variable name hwy) against the engine’s size (aka displacement displ). Click for solution # 1. ggplot(mpg, aes(x = displ, y = hwy)) + geom_point() There are a few vehicles with large engines that have unusually high fuel efficiency for such big engines. Colour the points by the type of car (the class variable). Can you explain these cars? Click for solution # sub part 1 ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = class)) Notice that 5 of the 6 points have a large engine and higher than expected efficiency are 2-seater cars, so these are most likely sports cars which are lighter and despite having large engines use slightly less fuel. Now remove the colouring but split the plot into facets where you have a graphic per car type. (Use facet_wrap() with class.) Click for solution # sub part 2 ggplot(mpg, aes(x = displ, y = hwy)) + facet_wrap(~ class) + geom_point() Add to this collection of plots the fuel efficiency for city driving, coloured in red. Update the y-axis to be called “Fuel efficiency” to reflect that it is not only the hwy variable plotted now. Click for solution # sub part 3 ggplot(mpg, aes(x = displ, y = hwy)) + facet_wrap(~ class) + geom_point() + geom_point(aes(y = cty), colour = &quot;red&quot;)+ ylab(&quot;Fuel efficiency&quot;) Note that we’re overriding the y mapping with the cty variable, and putting the colour argument outside the aesthetic because it applies to all these points and is not data dependent. Write the code to produce a scatterplot of highway fuel efficiency hwy against displacement displ coloured by drive type drv (front, rear, four). Overlay fitted regression lines coloured by drive type. Finally, overlay a single regression line, coloured black, based on all data. Click for solution # 2. ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = drv)) + geom_smooth(aes(colour = drv), method=lm) + geom_smooth(method=lm, colour = &quot;black&quot;) When producing this plot we need to remember the rules ggplot2 uses. We can’t put the colour in the ggplot() plot creation call, because then it will apply to all geoms (and we need the black smoother not to be split by drive train). Therefore, we put just x and y in the ggplot() call, add the points with the additional colour aesthetic, add a regression fit with the colour in an aesthetic so that we get a regression line per drive type, then add the black regression line with the colour not specified as an aesthetic because it applies to all the data (instead, just a direct argument). Produce a bar plot of the count of the number of each type of vehicle (class) in the data by using the Geom geom_bar(), with aesthetic x set to the vehicle type (NB: this question is to help you check if you are starting to understand the plotting system, because even though we didn’t show an example of a bar plot, this sentence alone should be enough information without needing to look at the documentation. The plotting system follows a coherent set of rules for all plot types!) Click for solution # 3. ggplot(mpg, aes(x = class)) + geom_bar() Make a second version where you also add an aesthetic fill which is set to the variable drv. What is this showing? Click for solution # 3. sub part ggplot(mpg, aes(x = class, fill = drv)) + geom_bar() Each bar is still the same height as in the first bar plot, but now it is broken down to show how many of each type of car is 4-wheel, front wheel and rear wheel drive. \\(~\\) 3.4 Exercise 3 (if time) The data used here represent Maths achievement scores of a subsample of subjects from the 1982 High School and Beyond Survey. The full dataset can be found within the package merTools. Click the link to read about the data set. The analysis starts by introducing the data and producing some visual representations. Read in the data from Andy’s Github page with sub_hsb &lt;- read.csv(file=&quot;https://andygolightly.github.io/teaching/MATH43515/sub_hsb.csv&quot;) Carry out the following operations for simple access of variables. data &lt;- sub_hsb mathach &lt;- data$mathach # Maths achievement score (response) ses &lt;- data$ses female &lt;- data$female school.f &lt;- as.factor(data$schid) Data inspection: head(data) ## schid minority female ses mathach size schtype meanses ## 1 1224 0 1 -1.528 5.876 842 0 -0.428 ## 2 1224 0 1 -0.588 19.708 842 0 -0.428 ## 3 1224 0 0 -0.528 20.349 842 0 -0.428 ## 4 1224 0 0 -0.668 8.781 842 0 -0.428 ## 5 1224 0 0 -0.158 17.898 842 0 -0.428 ## 6 1224 0 0 0.022 4.583 842 0 -0.428 Start with a linear regression as a baseline model. lm &lt;- lm(mathach~ses, data=data) summary(lm) ## ## Call: ## lm(formula = mathach ~ ses, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18.0019 -4.6006 0.0497 5.2174 16.0877 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.8864 0.1753 73.51 &lt;2e-16 *** ## ses 3.4530 0.2222 15.54 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.39 on 1327 degrees of freedom ## Multiple R-squared: 0.1539, Adjusted R-squared: 0.1533 ## F-statistic: 241.5 on 1 and 1327 DF, p-value: &lt; 2.2e-16 Visualise the linear relationship. ggplot(data = data, aes(x = ses, y = mathach))+ geom_point(size = 0.8, alpha = .8)+ geom_smooth(method=&quot;lm&quot;, se=FALSE, col=&quot;Red&quot;)+ ggtitle(&quot;Mathach vs. Ses&quot;) + xlab(&quot;Ses&quot;) + ylab(&quot;Mathach&quot;) Carry out further exploratory analysis of the data along the lines of the previous example. # ... End of lab! "],["multilevel-modelling-practical-3-week-4.html", "4 Multilevel Modelling Practical 3 (Week 4) 4.1 Instructions – start here! 4.2 Exercise 1 4.3 Exercise 2", " 4 Multilevel Modelling Practical 3 (Week 4) 4.1 Instructions – start here! Exercise 1 takes you through the analysis carried out in Lecture 4 of this module. Exercise 2 allows you to produce some additional analysis using the 1982 High School and Beyond Survey data introduced in the previous practical. We initially load the R packages haven, ggplot2, lme4 and lmerTest. Further R packages will be loaded where needed. require(haven) # to load the SPSS .sav file require(ggplot2) # used for production of graphs require(lme4) # used for fitting random effect models require(lmerTest) # used in hypothesis testing 4.2 Exercise 1 This is a continuation of Exercise 1 from the previous practical. Last week, we considered an exploratory analysis of the student popularity data set. We will now consider a two-level multilevel model for the response variable (popularity, \\(y\\)) using the extraversion covariate (\\(x\\)). 4.2.1 Preparation of the data set We prepare the data as previously: pop.rawdata &lt;- read_sav(file=&quot;https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/blob/master/chapter%202/popularity/SPSS/popular2.sav?raw=true&quot;) Re-label some columns as before: pop.data &lt;- pop.rawdata[,c(&quot;pupil&quot;, &quot;class&quot;, &quot;extrav&quot;, &quot;sex&quot;, &quot;texp&quot;, &quot;popular&quot;)] colnames(pop.data)&lt;- c(&quot;pupil&quot;, &quot;class&quot;, &quot;extraversion&quot;, &quot;gender&quot;, &quot;experience&quot;, &quot;popularity&quot;) head(pop.data) # we have a look at the first 6 observations ## # A tibble: 6 × 6 ## pupil class extraversion gender experience popularity ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 5 1 [girl] 24 6.3 ## 2 2 1 7 0 [boy] 24 4.9 ## 3 3 1 4 1 [girl] 24 5.3 ## 4 4 1 3 1 [girl] 24 4.7 ## 5 5 1 5 1 [girl] 24 6 ## 6 6 1 4 0 [boy] 24 4.7 \\(~\\) 4.2.2 Fitting the random intercept and slope model The model takes the form \\[y_{ij}=a + b x_{ij} + u_j +v_j x_{ij} +\\epsilon_{ij} \\] where \\(u_j\\sim N(0,\\sigma^2_u)\\), \\(v_j \\sim N(0,\\sigma^2_v)\\) and the independent error terms are \\(\\epsilon_{ij} \\sim N(0,\\sigma^2)\\). The following is the code to fit a random intercept and slope model (and summarise): model1 &lt;- lmer(formula = popularity ~ 1+ extraversion +(1+ extraversion|class), data = pop.data) summary(model1) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: popularity ~ 1 + extraversion + (1 + extraversion | class) ## Data: pop.data ## ## REML criterion at convergence: 5779.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.1961 -0.7291 0.0145 0.6817 3.2216 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## class (Intercept) 2.99680 1.7311 ## extraversion 0.02595 0.1611 -0.97 ## Residual 0.89495 0.9460 ## Number of obs: 2000, groups: class, 100 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.46106 0.20309 96.71010 12.12 &lt;2e-16 *** ## extraversion 0.49286 0.02545 89.75489 19.36 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## extraversin -0.917 ## optimizer (nloptwrap) convergence code: 0 (OK) ## Model failed to converge with max|grad| = 0.00663866 (tol = 0.002, component 1) Note the warning message about potential lack of convergence. A better optimiser should solve this issue: model1 &lt;- lmer(formula = popularity ~ 1+ extraversion +(1+ extraversion|class), data = pop.data, control = lmerControl(optimizer =&quot;Nelder_Mead&quot;)) summary(model1) If you execute the above code chunk, you’ll see that the difference in estimated coefficients is very small (typically 4th decimal place) making us less concerned about the initial warning. TASK: Interpret the summarised model output. Click for solution The expected popularity rises by 0.49286 per extra point of extraversion. There is considerable variation between classes: The random effect variances are \\(\\sigma^2_u=2.9968\\) and \\(\\sigma^2_v=0.02595\\). The random effects are strongly negatively correlated (-0.97): For classes where the popularity is generally larger, increasing extraversion will have less additional effect. \\(~\\) 4.2.3 Fitted lines by class The following R code plots the fitted regression lines for each class. pop.data$pred1 &lt;- predict(model1) ggplot(pop.data, aes(x= extraversion, y = popularity, col = class, group = class))+ geom_line(aes(y=pred1, group=class, col=class)) + scale_color_gradientn(colours = rainbow(100)) TASK: Predicted values are given by \\[\\hat{y}_{ij}=\\hat{a}+\\hat{b}x_{ij}+\\hat{u}_j+\\hat{v}_jx_{ij}\\]. The first fitted value is \\(\\hat{y}_{11}=\\) 5.1311949. By using fixef to extract the fixed effects \\(\\hat{a}\\) and \\(\\hat{b}\\), and ranef to extract the random effects \\(\\hat{u}_1\\) and \\(\\hat{v}_1\\), directly calculate \\(\\hat{y}_{11}\\) and make sure it agrees with the above value. Click for solution fix &lt;- as.numeric(fixef(model1)) ranef1 &lt;- as.numeric(ranef(model1)$class[1,]) newx &lt;- c(1, pop.data$extraversion[1]) fix%*%newx +ranef1%*%newx ## [,1] ## [1,] 5.131195 \\(~\\) 4.2.4 The intercept-only / empty model and ICC Recall that the empty model is \\[y_{ij}=\\gamma_0 + u_j +\\epsilon_{ij}\\] The following code fits the empty model and summarises output. intercept.only.model &lt;- lmer(formula = popularity ~ 1 + (1|class),data = pop.data) summary(intercept.only.model) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: popularity ~ 1 + (1 | class) ## Data: pop.data ## ## REML criterion at convergence: 6330.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.5655 -0.6975 0.0020 0.6758 3.3175 ## ## Random effects: ## Groups Name Variance Std.Dev. ## class (Intercept) 0.7021 0.8379 ## Residual 1.2218 1.1053 ## Number of obs: 2000, groups: class, 100 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 5.07786 0.08739 98.90973 58.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 TASK: Calculate and interpret the intra-class correlation (ICC). Click for solution Method 1: read off the estimates of \\(\\sigma^2_u\\) and \\(\\sigma^2\\) from the output above. rho= 0.7021/(0.7021+1.2218) rho ## [1] 0.3649358 Method 2: extract the relevant estimates directly: vars &lt;- as.data.frame(summary(intercept.only.model)$varcor)$vcov (rho &lt;- vars[1]/sum(vars)) ## [1] 0.3649386 Method 3: the following package can also be used to calculate ICC. require(performance) # https://easystats.github.io/performance/reference/icc.html icc(intercept.only.model) ## # Intraclass Correlation Coefficient ## ## Adjusted ICC: 0.365 ## Unadjusted ICC: 0.365 \\(~\\) 4.2.5 The random intercept model (with covariate) Now let’s look at the random intercept model with a fixed effect for extraversion. The model is \\[y_{ij}=a+b x_{ij}+u_j+\\epsilon_{ij}\\] We can fit and summarise via: model0 &lt;- lmer(formula = popularity ~ 1+ extraversion +(1|class), data = pop.data) summary(model0) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: popularity ~ 1 + extraversion + (1 | class) ## Data: pop.data ## ## REML criterion at convergence: 5832.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.0644 -0.7267 0.0165 0.7088 3.3587 ## ## Random effects: ## Groups Name Variance Std.Dev. ## class (Intercept) 0.8406 0.9168 ## Residual 0.9304 0.9646 ## Number of obs: 2000, groups: class, 100 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.542e+00 1.411e-01 4.380e+02 18.01 &lt;2e-16 *** ## extraversion 4.863e-01 2.015e-02 1.965e+03 24.13 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## extraversin -0.745 TASK: Add a column to the pop.data data frame called pred0 containing the predicted responses from this model. Hence, produce a plot of the regression lines (obtained from this model) for each class (also coloured by class). Click for solution The following R code generates predicred responses and plots the fitted regression lines for each class. pop.data$pred0 &lt;- predict(model0) ggplot(pop.data, aes(x= extraversion, y = popularity, col = class, group = class))+ geom_line(aes(y=pred0, group=class, col=class)) + scale_color_gradientn(colours = rainbow(100)) Notice that all the slopes are the same, as expected! Whether or not random slopes are needed (and how we decide this) will be explored later in the course. \\(~\\) Harder (deeper thinking): please spend at least 15 mins thinking about the following before uncovering the solution details (talk also to each other and Andy about it). We have a class level covariate - teacher experience. How can we include this in the model above (random intercept model)? One possibility is to try to use this covariate to explain some of the variation in the random intercept values. The random intercept model has \\(a_j=a+u_j\\) where \\(u_j\\sim N(0,\\sigma^2_u)\\). Let \\(\\text{exp}_j\\) denote teacher experience (in years) for class \\(j\\). How should we modify \\(a_j\\) to include the \\(\\text{exp}\\) covariate? Write out the resulting model in the form \\(y_{ij}= \\ldots\\) and fit the model in R. Is the experience covariate needed? Click for solution “Regress” the \\(a_j\\) on \\(\\text{exp}\\) to give \\[a_j = a + \\alpha \\text{exp}_j +u_j\\] where \\(u_j\\sim N(0,\\sigma^2_u)\\). Hence, the full model becomes \\[y_{ij}=a +\\alpha \\text{exp}_j + b x_{ij} + u_j + \\epsilon_{ij} \\] We can fit this model in R via: model2 &lt;- lmer(formula = popularity ~ 1+ extraversion + experience +(1|class), data = pop.data) summary(model2) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: popularity ~ 1 + extraversion + experience + (1 | class) ## Data: pop.data ## ## REML criterion at convergence: 5776.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2000 -0.7193 0.0211 0.6995 3.3732 ## ## Random effects: ## Groups Name Variance Std.Dev. ## class (Intercept) 0.4251 0.6520 ## Residual 0.9303 0.9645 ## Number of obs: 2000, groups: class, 100 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.035e+00 2.076e-01 2.381e+02 4.985 1.19e-06 *** ## extraversion 5.037e-01 2.017e-02 1.962e+03 24.976 &lt; 2e-16 *** ## experience 9.910e-02 1.056e-02 1.018e+02 9.385 1.90e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) extrvr ## extraversin -0.610 ## experience -0.799 0.142 A test of the null hypothesis that \\(\\alpha=0\\) (after adjusting for extraversion) would be rejected (easily) at the \\(5\\%\\) level. It looks like the experience covariate is needed here. \\(~\\) Even deeper: The random intercept and slope model has \\(b_j=b+v_j\\) where \\(v_j\\sim N(0,\\sigma^2_v)\\). How should we modify \\(b_j\\) to include the \\(\\text{exp}\\) covariate? Write out the resulting model in the form \\(y_{ij}= \\ldots\\). If done correctly, this should give an interaction term of the form \\(\\text{exp}_j x_{ij}\\). \\(~\\) 4.3 Exercise 2 4.3.1 Preparation This is a continuation of Exercise 3 from the previous practical. We continue now with the analysis of the Maths achievement scores from the 1982 High School and Beyond Survey. As on the last worksheet, load the data into your workspace via: sub_hsb &lt;- read.csv(file=&quot;https://andygolightly.github.io/teaching/MATH43515/sub_hsb.csv&quot;) Carry out the following operations for simple access of variables. data &lt;- sub_hsb mathach &lt;- data$mathach # Maths achievement score (response) ses &lt;- data$ses female &lt;- data$female school.f &lt;- as.factor(data$schid) #I&#39;m using .f for factor in the variable name colnames(data) ## [1] &quot;schid&quot; &quot;minority&quot; &quot;female&quot; &quot;ses&quot; &quot;mathach&quot; &quot;size&quot; &quot;schtype&quot; &quot;meanses&quot; Recall that the full dataset can be found within the package merTools. Click the link to read about the data set. \\(~\\) 4.3.2 The random intercept model As in Exercise 1, to specify random effects, apply the same formula as that for linear regression using the function lmer instead of lm. We begin with the random intercept model, including a fixed effect for ses (a measure of socio-economic status). A random intercept for the upper level (in this case, school) will be coded as (1|school.f). model.rint &lt;- lmer(mathach ~ ses + (1 | school.f), data=data) summary(model.rint) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: mathach ~ ses + (1 | school.f) ## Data: data ## ## REML criterion at convergence: 8601 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.81268 -0.70959 -0.03616 0.76678 2.74101 ## ## Random effects: ## Groups Name Variance Std.Dev. ## school.f (Intercept) 6.339 2.518 ## Residual 36.119 6.010 ## Number of obs: 1329, groups: school.f, 30 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 12.8865 0.4908 26.4805 26.256 &lt;2e-16 *** ## ses 2.1202 0.2536 1234.9858 8.359 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## ses -0.010 TASK: Interpret the output, find the ICC. \\(~\\) We now extract and visualize fitted values vs. the linear model: to do this with ggplot, add the main plot (ggplot(...)) including a line (geom_line()) indicating the predictions acquired from predict(Model1) and the grouping structure (school). Note that geom_point() includes the data points for reference. data$pred1 &lt;- predict(model.rint) model1_int &lt;- ggplot(data, aes(ses,mathach))+ geom_line(aes(y=pred1,group=school.f, col=school.f))+ geom_point(aes(ses,mathach, col=school.f), size = 0.8, alpha = .8)+ geom_smooth(method=&quot;lm&quot;, se=FALSE, col=&quot;Red&quot;)+ ggtitle(&quot;Multilevel model (Model1)&quot;, subtitle=&quot;Random Intercept only&quot;) + xlab(&quot;Ses&quot;) + ylab(&quot;Mathach&quot;)+ theme(legend.position = &quot;none&quot;) model1_int The results of the above regression illustrate the importance of accounting for a multilevel structure. It is evident that had we used a simple linear regression (red line), we would have inadvertently overestimated the mean effect of ses. This is also easy to see by inspecting the model summary of the linear model, where ses has a coefficient of 3.45 while in the multilevel specification a coefficient of 2.12 with a random intercept variance that is considerably greater than zero with a value of 6.33. \\(~\\) 4.3.3 Diagnostics Now we visualise results and conduct some diagnostic checks, in order to check for the adequacy of modelling assumptions. ALthough we have not (up until now) considered diagnostics in the multilevel context, we proceed as in the linear regression case, by checking normality of residuals and additionally, normality of the random effects! We start by plotting the residuals vs the fitted values. plot(model.rint) Ideally, we should see here just random noise, that is no pattern at all. This is reasonably fulfilled, however there is impression of a diagonal field-like shape spanning from the top left to the bottom right. This likely indicates that a predictor variable which would have explained this slope has been omitted. \\(~\\) Continue with inspection of model assumptions by looking at quantile-quantile plots for the residuals and random effects: qqnorm(resid(model.rint)) qqline(resid(model.rint), col = &quot;red&quot;) qqnorm(ranef(model.rint)$school.f[,1]) # check random effects qqline(ranef(model.rint)$school.f[,1], col = &quot;red&quot;) The QQ plots also look fairly acceptable (close to y=x line), indicating that the assumption of normality of the error terms and of the random effects is reasonably fulfilled. \\(~\\) 4.3.4 Include a second fixed effect variable: gender We will now perform multilevel modelling using random intercepts, this time including the dummy variable for female: model2.rint &lt;- lmer(mathach ~ ses + female + (1 | school.f), data=data) #summary(model2.rint) #uncomment if you&#39;d like to interogate the model output \\(~\\) We will plot the fitted values, categorised by gender. We want two plots, side-by-side, showing the fitted lines for each school. data$pred2 &lt;- predict(model2.rint) gender_names &lt;- c(&quot;0&quot; =&quot;Male&quot;,&quot;1&quot;=&quot;Female&quot;) #define labels for facet_grid model2_int &lt;- ggplot(data,aes(ses,mathach))+ geom_line(aes(y=pred2,group=school.f, col=school.f))+ geom_point(aes(ses,mathach, col=school.f), size = 0.8, alpha = .8)+ geom_smooth(method=&quot;lm&quot;, se=FALSE, col=&quot;Red&quot;)+ ggtitle(&quot;Multilevel model (Model2)&quot;, subtitle=&quot;By Gender&quot;) + facet_grid(~female, labeller = as_labeller(gender_names))+ xlab(&quot;Ses&quot;) + ylab(&quot;Mathach&quot;)+ theme(legend.position = &quot;none&quot;) model2_int There is a lot going on here! Try to understand each line, and what is being plotted. Consider writing out the mathematical form of the model, or discuss with each other / Andy as to what this form takes. ** End of lab! "],["multilevel-modelling-practical-4-week-5.html", "5 Multilevel Modelling Practical 4 (Week 5) 5.1 Instructions – start here! 5.2 Exercise 1: Analysis of the Active Time study data (lecture 5)", " 5 Multilevel Modelling Practical 4 (Week 5) 5.1 Instructions – start here! In this lab we will analyse the ``Active Time’’ data set considered at the end of the Lecture 5 slides. This lab is a little shorter than previous labs to allow time to understand the 3-level structure of the data and appropriate models. We initially load the packages we need. require(lme4) require(lmerTest) require(ggplot2) 5.2 Exercise 1: Analysis of the Active Time study data (lecture 5) Read in the data as follows. Sim3level &lt;- read.csv(&quot;https://andygolightly.github.io/teaching/MATH43515/Sim3level.csv&quot;) Visually inspect the data frame. head(Sim3level) ## Math ActiveTime ClassSize Classroom School StudentID ## 1 55.42604 0.06913359 18 1 Sch1 1 ## 2 54.34306 0.08462063 18 1 Sch1 2 ## 3 61.42570 0.12994557 18 1 Sch1 3 ## 4 56.12271 0.74613202 18 1 Sch1 4 ## 5 53.34900 0.03887918 18 1 Sch1 5 ## 6 57.99773 0.68563542 18 1 Sch1 6 We have the following variables: Math maths score on \\((0,100)\\) (response variable) ActiveTime a standardised (to \\((0,1)\\)) measure of physical activity (covariate) ClassSize the size of a given class (covariate) Classroom Class identifier School School identifier StudentID student identifier We have a 3-level structure with students nested in classes in schools. Plainly, we have ActiveTime at the student level and ClassSize at the class level. We can see the number of schools, classrooms within each school and number of students in each class via tapply(Sim3level$Classroom,Sim3level$School,table) ## $Sch1 ## ## 1 2 3 4 5 6 7 8 9 10 ## 18 14 20 14 15 18 20 16 12 14 ## ## $Sch2 ## ## 1 2 3 4 5 6 7 8 ## 18 18 15 21 18 20 20 18 ## ## $Sch3 ## ## 1 2 3 4 5 6 7 8 9 10 11 12 ## 19 24 20 24 23 20 24 20 19 23 24 21 For example, school 1 has 10 classes, with student numbers ranging from 12 to 20. \\(~\\) 5.2.1 How important is group structure? (VPCs and ICCs) Let \\(y_{ijk}\\) denote the response maths for student \\(i\\) in class \\(j\\) in school \\(k\\). The random intercept only (empty) model is: \\[y_{ijk} = \\gamma_0 +u_{jk}+v_k+\\epsilon_{ijk}\\] where \\(u_{jk}\\sim N(0,\\sigma^2_u)\\) is the random effect for classroom, \\(v_k\\sim N(0,\\sigma^2_v)\\) is the random effect for school and \\(\\epsilon_{ijk}\\sim N(0,\\sigma^2)\\) is the usual error term. All random variables here are assumed independent. \\(~\\) We fit and summarise the random intercept only (empty model) via: Model.0 &lt;- lmer(Math ~ 1 +(1|School) +(1|School:Classroom), data=Sim3level) summary(Model.0) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: Math ~ 1 + (1 | School) + (1 | School:Classroom) ## Data: Sim3level ## ## REML criterion at convergence: 3776.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.5226 -0.6752 0.0000 0.6549 2.7502 ## ## Random effects: ## Groups Name Variance Std.Dev. ## School:Classroom (Intercept) 44.93 6.703 ## School (Intercept) 91.85 9.584 ## Residual 37.22 6.101 ## Number of obs: 570, groups: School:Classroom, 30; School, 3 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 44.420 5.677 2.016 7.825 0.0156 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can then extract the estimated variance components from the model via: REsummary &lt;- as.data.frame(VarCorr(Model.0)) REsummary ## grp var1 var2 vcov sdcor ## 1 School:Classroom (Intercept) &lt;NA&gt; 44.93358 6.703252 ## 2 School (Intercept) &lt;NA&gt; 91.85144 9.583915 ## 3 Residual &lt;NA&gt; &lt;NA&gt; 37.21794 6.100651 (Note: Alternatively you could use summary(Model.0)$varcor.) TASK: Find and interpret all VPC and ICC values. Click for solution VPC estimates sig &lt;- REsummary$vcov[3] #Residual variance sigv &lt;- REsummary$vcov[2] #RE variance for school sigu &lt;- REsummary$vcov[1] #RE variance for class totalvar &lt;- sum(REsummary$vcov) #total variance vpc.school &lt;- sigv/totalvar vpc.class &lt;- sigu/totalvar vpc.school ## [1] 0.5278728 vpc.class ## [1] 0.2582346 ICC estimates icc.school &lt;- sigv/totalvar icc.class &lt;- (sigu+sigv)/totalvar icc.school ## [1] 0.5278728 icc.class ## [1] 0.7861074 We have 26% response variation at the class level and 53% at the school level. Variability between schools is more than between classes. The ICC for class is 79% i.e. very large! Recall that this gives the correlation between two students in the same classroom in the same school. This correlation is largely “driven” by the school level ICC (53%) which is the correlation between two students in the same school but different classrooms. \\(~\\) 5.2.2 Three level Model with explanatory variables The random intercept model with covariates for ActiveTime and ClassSize is given by \\[y_{ijk}=a+b_{1}\\text{ActiveTime}_{ijk}+b_2\\text{Class}_{jk}+u_{jk}+v_{k}+\\epsilon_{ijk}\\] We fit this model with the code: Model.1 &lt;- lmer(Math ~ ActiveTime+ClassSize +(1|School) +(1|School:Classroom), data=Sim3level) summary(Model.1) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: Math ~ ActiveTime + ClassSize + (1 | School) + (1 | School:Classroom) ## Data: Sim3level ## ## REML criterion at convergence: 3367.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.3086 -0.6518 -0.0488 0.6330 3.0744 ## ## Random effects: ## Groups Name Variance Std.Dev. ## School:Classroom (Intercept) 46.55 6.823 ## School (Intercept) 83.98 9.164 ## Residual 17.54 4.188 ## Number of obs: 570, groups: School:Classroom, 30; School, 3 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 41.1849 11.9131 17.8660 3.457 0.00284 ** ## ActiveTime 14.9476 0.6066 539.8898 24.643 &lt; 2e-16 *** ## ClassSize -0.2110 0.5634 27.9933 -0.374 0.71089 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ActvTm ## ActiveTime -0.030 ## ClassSize -0.889 0.007 Note that the above can be equivalently executed via Model.1 &lt;- lmer(Math ~ ActiveTime+ClassSize +(1|School/Classroom), data=Sim3level) 5.2.3 Comparison of empty model with model with explanatory variables To test the null hypothesis that \\(b_1=0\\) and \\(b_{2}=0\\) against an alternative that at least one of these fixed effects is not 0, we can use anova(Model.0, Model.1) ## refitting model(s) with ML (instead of REML) ## Data: Sim3level ## Models: ## Model.0: Math ~ 1 + (1 | School) + (1 | School:Classroom) ## Model.1: Math ~ ActiveTime + ClassSize + (1 | School) + (1 | School:Classroom) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## Model.0 4 3789.8 3807.2 -1890.9 3781.8 ## Model.1 6 3385.6 3411.7 -1686.8 3373.6 408.21 2 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Plainly, the null hypothesis is rejected, suggesting that explanatory variables are needed. BUT, do we need both? Look at the output of: summary(Model.1) Is ClassSize needed? I think not! 5.2.4 Further analysis (bottom up approach) TASK: How does the model without the ClassSize covariate (say Model.2) compare to Model.1? This question is really asking is how the deviance changes from Model.1 to Model.2. We know that the simpler Model.2 will have a bigger deviance than Model.1. BUT, if this difference is very small, we should prefer the simpler model. Test this hypothesis formally using the anova() function (after first creating Model.2 using lmer()). Click for solution Remove ClassSize and refit: Model.2 &lt;- lmer(Math ~ ActiveTime +(1|School/Classroom), data=Sim3level) summary(Model.2) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: Math ~ ActiveTime + (1 | School/Classroom) ## Data: Sim3level ## ## REML criterion at convergence: 3367.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.3082 -0.6504 -0.0510 0.6339 3.0697 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Classroom:School (Intercept) 44.71 6.686 ## School (Intercept) 92.65 9.626 ## Residual 17.54 4.188 ## Number of obs: 570, groups: Classroom:School, 30; School, 3 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 37.2207 5.7037 2.0272 6.526 0.0219 * ## ActiveTime 14.9492 0.6065 539.9821 24.647 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## ActiveTime -0.051 Now compare models with and without the ClassSize fixed effect: anova(Model.2, Model.1) ## refitting model(s) with ML (instead of REML) ## Data: Sim3level ## Models: ## Model.2: Math ~ ActiveTime + (1 | School/Classroom) ## Model.1: Math ~ ActiveTime + ClassSize + (1 | School) + (1 | School:Classroom) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## Model.2 5 3383.9 3405.6 -1686.9 3373.9 ## Model.1 6 3385.6 3411.7 -1686.8 3373.6 0.279 1 0.5974 The change in deviance is tiny! We have insufficient evidence against the null hypothesis that the fixed effect for ClassSize is zero. We therefore retain the null and conclude that ClassSize is not needed. \\(~\\) TASK: Is a random slope needed (allowing a different slope for ActiveTime in each class)? Create Model.3 using lmer() with the inclusion of a random slope for ActiveTime. Test the null hypothesis that the random slope variance is zero using ranova(Model.3). Click for solution Now let’s add a random slope for ActiveTime: Model.3 &lt;- lmer(Math ~ ActiveTime +(1|School) +(1+ActiveTime|School:Classroom), data=Sim3level) Now test to see if the random slope variance can be assumed zero or not: ranova(Model.3) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## Math ~ ActiveTime + (1 | School) + (1 + ActiveTime | School:Classroom) ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 7 -1666.0 3346.0 ## (1 | School) 6 -1674.7 3361.4 17.355 1 3.101e-05 *** ## ActiveTime in (1 + ActiveTime | School:Classroom) 5 -1684.0 3377.9 35.928 2 1.579e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 which suggests that the random slope is needed. \\(~\\) TASK: Is the resulting model a good fit (check diagnostics)? Try plot(Model.3) then use resid() and ranef() to get estimated residuals and random effects. For the latter, note that a list will be returned, with the first list item holding the estimated intercepts and slopes the class level, and the second list item holding the estimated intercepts at the school level. Click for solution Diagnostics: plot(Model.3) qqnorm(resid(Model.3)) qqline(resid(Model.3)) qqnorm(ranef(Model.3)[[1]][,1]) qqline(ranef(Model.3)[[1]][,1]) qqnorm(ranef(Model.3)[[1]][,2]) qqline(ranef(Model.3)[[1]][,2]) #qqnorm(ranef(Model.3)[[2]][,1]) #qqline(ranef(Model.3)[[2]][,1]) #Omit as only 3 schools! I think the fit looks reasonable - why? \\(~\\) TASK (harder): How can we visualise the fit of Model.3? Recall the predict function and use ggplot() to produce a graph showing fitted lines for all classrooms in school 1. Click for solution Sim3level$pred &lt;- predict(Model.3) ggplot(Sim3level[Sim3level$School==&quot;Sch1&quot;,], aes(x=ActiveTime,y=Math,col=Classroom,group=Classroom))+ geom_line(aes(y=pred))+ scale_color_gradientn(colours=rainbow(100)) \\(~\\) Understanding the model: Model.3 can be written mathematically as \\[y_{ijk}=a+b\\text{ActiveTime}_{ijk}+w_{jk}\\text{ActiveTime}_{ijk}+u_{jk}+v_{k}+\\epsilon_{ijk}\\] with \\(w_{jk}\\sim N(0,\\sigma^2_w)\\) representing the random slopes (we get a different one for each classroom and school combination). We can visualise the fitted model in all 3 schools: Click for the code to see the above Sim3level$pred &lt;- predict(Model.3) ggplot(Sim3level, aes(x=ActiveTime,y=Math,col=Classroom,group=Classroom))+ facet_wrap(~School)+ geom_line(aes(y=pred))+ scale_color_gradientn(colours=rainbow(100)) The plots above make clear the role of the random intercept and slope terms at the classroom level; the fitted line for each classroom \\(j\\) within a school \\(k\\) has its own intercept \\(a+u_{jk}+v_{k}\\) and slope \\(b+w_{jk}\\). Hence, \\(a\\) gives the average intercept value, the \\(v_{k}\\) term allows for differences in intercept values between schools and the \\(u_{jk}\\) allows for further intercept differences between classrooms within schools. Similary, the random slope \\(w_{jk}\\) allows for a different linear relationship between the response and covariate for each classroom-school combination. What else can you say that is interesting? Try interpreting the effect of \\(\\text{ActiveTime}\\) on the expected response. Look at the correlation between the \\(u_{jk}\\) and \\(w_{jk}\\) (from the model summary). Does it make sense in light of the plot above? We could try including a random slope on \\(\\text{ActiveTime}\\) at the school level. This will more than likely give a “boundary (singular) fit” warning, which usually indicates over-fitting. This can happen if there are too few observations to reliably estimate the parameters at a particular level (and note that we only have 3 schools here). In this case, reducing the complexity of the model (by removing the higher level random slope) is recommended. \\(~\\) End of lab! "],["multilevel-modelling-practical-5-week-6.html", "6 Multilevel Modelling Practical 5 (Week 6) 6.1 Instructions - start here!", " 6 Multilevel Modelling Practical 5 (Week 6) 6.1 Instructions - start here! This lab involves the analysis of a longitudinal data set (full details below). Let’s begin by loading the necessary packages and data: require(lme4) require(lmerTest) require(ggplot2) require(haven) 6.1.1 Overview The analysis starts by introducing the longitudinal data and some visual representations. This particular dataset was chosen for three primary reasons: It illustrates the basic notion of “time” in a slightly different context with the hope of a more intuitive understanding. The time variable is age and is continuous (contrary to most cases where it is presented as discrete) to showcase that what defines time is the repeated values within children, rather than a discrete definition and format. It binds well to the notion of covariance. When defined as a random intercept and random slope model, it has a fanning-out form that is distinct enough to produce a positive covariance, allowing for an intuitive explanation both illustratively and quantitatively of what the sign on a covariance implies. There is a non-linear relationship between the response and time, which presents us with an opportunity to showcase how to deal with it. The practical continues by comparing the random intercept and full random effects models, again using ggplot2. It then uses the full random effects model as the primary model to conduct diagnostic checks where non-linearity is discovered in the residuals plot and then countered using a squared age variable. It is also shown how one can extract the variance-covariance matrix for inspection and how to use it to build the Intraclass Correlation Coefficient. Some basic model assumptions are also tested using visual representations. 6.1.2 Multilevel modelling with longitudinal data The data set is comprised of child weight for children in a British community who were weighed up to four times, roughly between the ages of 6 weeks and 27 months. (It represents a random sample of data previously analyzed by Goldstein (1986) and Prosser, Rasbash, and Goldstein (1991).) Download the file childweight.RData from Ultra and place it into your working directory. (Consult Practical 3 if you need further instructions on how to do this.) Then load it into your workspace via ` \\(~\\) load(&quot;childweight.RData&quot;) # Insert directory as needed data &lt;- childweight #Or uncomment the following if there are issues loading the workspace #data &lt;- read.csv(&quot;https://andygolightly.github.io/teaching/MATH43515/childweight.csv&quot;)[,-1] weight &lt;- data$weight age &lt;- data$age birthw &lt;- data$brthwt girl &lt;- data$girl id.f &lt;- as.factor(data$id) 6.1.2.1 Brief exploratory analysis Data summary and inspection: head(data) ## # A tibble: 6 × 5 ## id age weight brthwt girl ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; ## 1 45 0.137 5.17 4140 0 [boy] ## 2 45 0.657 10.9 4140 0 [boy] ## 3 45 1.22 13.1 4140 0 [boy] ## 4 45 1.43 13.2 4140 0 [boy] ## 5 45 2.27 15.9 4140 0 [boy] ## 6 258 0.192 5.30 3155 1 [girl] summary(data) ## id age weight brthwt girl ## Min. : 45 Min. :0.1150 Min. : 3.100 Min. :1575 Min. :0.0000 ## 1st Qu.:1271 1st Qu.:0.6461 1st Qu.: 7.008 1st Qu.:2807 1st Qu.:0.0000 ## Median :2351 Median :0.9966 Median : 9.071 Median :3120 Median :0.0000 ## Mean :2491 Mean :1.0806 Mean : 8.837 Mean :3106 Mean :0.4949 ## 3rd Qu.:3704 3rd Qu.:1.4709 3rd Qu.:10.890 3rd Qu.:3390 3rd Qu.:1.0000 ## Max. :4975 Max. :2.5462 Max. :17.200 Max. :4270 Max. :1.0000 Although in most cases of longitudinal analysis you will encounter discrete categorical time values (i.e. 1, 2, 3,…) in this setting, time is not discrete but continuous with differing values between children. This feature however, does not necessarily imply that any additional methodology is needed to handle this. \\(~\\) Let’s plot the data by visualising the linear relationship. ggplot(data = data, aes(x = age, y = weight))+ geom_point(size = 1.2, alpha = .8)+ geom_smooth(method=&quot;lm&quot;, se=FALSE, col=&quot;Red&quot;)+ labs(title = &quot;Weight vs. Age&quot;) \\(~\\) We can also re-plot the relationship, this time inspecting group effects and the potential need for a multilevel model. TASK: Identify the number of levels in this data set, and the covariate(s) at each level. Click for solution We have two levels (time nested inside individuals). The age variable is playing the role of time here. Hence, weight, birthw and girl are all at the individual level (top level of the hierarchy). 6.1.2.2 Random intercept model Let’s fit a multilevel model with random intercepts and a binary coavriate girl. The model takes the form \\[y_{ti} = a+u_i+ b_1 T_{ti}+b_2\\text{girl}_{i} +\\epsilon_{ti}\\] We fit the model via: lmodel &lt;- lmer(weight ~ age + girl + (1 | id), data=data) summary(lmodel) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: weight ~ age + girl + (1 | id) ## Data: data ## ## REML criterion at convergence: 694.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.26782 -0.64129 -0.02437 0.72794 2.35999 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.5035 0.7095 ## Residual 1.5378 1.2401 ## Number of obs: 198, groups: id, 68 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 5.5149 0.2152 123.2548 25.630 &lt; 2e-16 *** ## age 3.3888 0.1153 148.5110 29.389 &lt; 2e-16 *** ## girl -0.7159 0.2499 64.9110 -2.865 0.00562 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) age ## age -0.573 ## girl -0.575 -0.006 \\(~\\) Now extract and visualize the fitted values vs. the linear model: data$pred1 &lt;- predict(lmodel) lmodel_int &lt;- ggplot(data, aes(age,weight)) + geom_line(aes(y=pred1,group=id.f, col=id.f)) + geom_point(aes(age,weight,col=id.f)) + geom_smooth(method=&quot;lm&quot;, se=FALSE, col=&quot;Red&quot;) + ggtitle(&quot;Multilevel Model&quot;, subtitle=&quot;Random Intercept-only&quot;) + xlab(&quot;Age (Time)&quot;) + ylab(&quot;Weight&quot;) + theme(legend.position = &quot;none&quot;) lmodel_int 6.1.2.3 Adding a random slope for time A multilevel model with both random intercepts and a random slope for time can be fitted thus: lmodel2 &lt;- lmer(weight ~ age + girl + (1 + age | id), data=data) summary(lmodel2) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: weight ~ age + girl + (1 + age | id) ## Data: data ## ## REML criterion at convergence: 684.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.38416 -0.69583 -0.04232 0.73479 2.13691 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.05702 0.2388 ## age 0.20709 0.4551 1.00 ## Residual 1.36994 1.1704 ## Number of obs: 198, groups: id, 68 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 5.4293 0.1869 121.3239 29.051 &lt; 2e-16 *** ## age 3.4593 0.1264 70.9320 27.362 &lt; 2e-16 *** ## girl -0.6354 0.2316 71.3148 -2.744 0.00767 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) age ## age -0.488 ## girl -0.612 -0.006 \\(~\\) We visualize the fitted values: data$pred2 &lt;- predict(lmodel2) lmodel_int_sl &lt;- ggplot(data,aes(age,weight)) + geom_line(aes(y=pred2,group=id.f, col=id.f)) + geom_point(aes(age,weight, col=id.f)) + geom_smooth(method=&quot;lm&quot;, se=FALSE, col=&quot;Red&quot;)+ ggtitle(&quot;Multilevel model (lmodel2)&quot;, subtitle=&quot;Random Intercept and Slope&quot;) + xlab(&quot;Age (Time)&quot;) + ylab(&quot;Weight&quot;)+ theme(legend.position = &quot;none&quot;) lmodel_int_sl \\(~\\) Let’s extract and inspect the variance-covariance matrix. Var_Cov_matrix &lt;- as.data.frame(VarCorr(lmodel2)) Var_Cov_matrix ## grp var1 var2 vcov sdcor ## 1 id (Intercept) &lt;NA&gt; 0.05701865 0.2387858 ## 2 id age &lt;NA&gt; 0.20708864 0.4550699 ## 3 id (Intercept) age 0.10866423 0.9999999 ## 4 Residual &lt;NA&gt; &lt;NA&gt; 1.36994491 1.1704465 The positive covariance re-affirms the fanning out pattern observed. The higher the predicted weight at baseline time (that is, higher child intercept), the higher the weight will be as time passes (i.e. a steeper child time slope). \\(~\\) Let’s look at a visual comparison between the random intercept vs random intercept and slope model. Make sure you understand the following code: vars &lt;- c(&quot;id&quot;,&quot;age&quot;,&quot;weight&quot;) data_pred1 &lt;- cbind(data[,vars],data[,&quot;pred1&quot;],group=1) names(data_pred1)[4] &lt;- &quot;pred&quot; data_pred2 &lt;- cbind(data[,vars],data[,&quot;pred2&quot;],group=2) names(data_pred2)[4] &lt;- &quot;pred&quot; data_comp &lt;- rbind(data_pred1,data_pred2) model_names &lt;- c(&quot;1&quot;=&quot;Random Intercept-only&quot;,&quot;2&quot;=&quot;Random Intercept and Slope&quot;) ggplot(data_comp, aes(age,weight)) + geom_line(aes(y=pred,group=as.factor(id), col=as.factor(id))) + geom_point(aes(age,weight, col=as.factor(id))) + geom_smooth(method=&quot;lm&quot;, se=FALSE, col=&quot;Red&quot;)+ facet_wrap(~group, labeller = as_labeller(model_names)) + ggtitle(&quot;Multilevel Model Comparison&quot;) + xlab(&quot;Age (Time)&quot;) + ylab(&quot;Weight&quot;) + theme(legend.position = &quot;none&quot;) TASK: Is the random slope on time needed? Perform an appropriate test. Click for solution ranova(lmodel2) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## weight ~ age + girl + (1 + age | id) ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 7 -342.05 698.10 ## age in (1 + age | id) 5 -347.24 704.48 10.389 2 0.005547 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 There is strong) evidence to reject the null hypothesis that the slope variance is zero. We need the random slopes! \\(~\\) 6.1.2.4 Dealing with the nonlinear relationship Given that the more complex model lmodel2 captures non-zero variance in random intercept and slope parameters, we will continue with it as our main model. Are the model assumptions valid? We will begin by inspecting the residuals. plot(lmodel2) It is evident that the plot suggests an underlying non-linear structure. \\(~\\) In order to correct the non-linearity observed, we perform multilevel modelling again, this time including a non-linear term for age. lmodel3 &lt;- lmer(weight ~ age + c(age*age) + girl + (1 + age | id), data=data) summary(lmodel3) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: weight ~ age + c(age * age) + girl + (1 + age | id) ## Data: data ## ## REML criterion at convergence: 518 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.04189 -0.44260 -0.03241 0.41940 2.66968 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.3781 0.6149 ## age 0.2681 0.5178 0.14 ## Residual 0.3296 0.5741 ## Number of obs: 198, groups: id, 68 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 3.79550 0.16815 85.13224 22.573 &lt; 2e-16 *** ## age 7.69844 0.23985 130.74444 32.096 &lt; 2e-16 *** ## c(age * age) -1.65773 0.08859 111.71023 -18.711 &lt; 2e-16 *** ## girl -0.59838 0.19997 57.23067 -2.992 0.00408 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) age c(*ag) ## age -0.543 ## c(age*age) 0.502 -0.929 ## girl -0.588 -0.008 0.007 \\(~\\) We again inspect the residuals vs fitted values. plot(lmodel3) It is evident that the non-linearity has been controlled for and residuals look much more acceptable. \\(~\\) We continue with inspection of model assumptions. i.e. normally distributed residuals and random effects. qqnorm(resid(lmodel3)) qqline(resid(lmodel3), col = &quot;red&quot;) qqnorm(ranef(lmodel3)$id[,1]) qqline(ranef(lmodel3)$id[,1], col = &quot;red&quot;) The QQ Plots also look fairly acceptable (close to y=x line). TASK: Visualise the fit of lmodel3, with separate plots for girls vs boys. Hint: first use predict(lmodel3) to create a new column in data. Click for solution data$pred3 &lt;- predict(lmodel3) lmodel_int_s2 &lt;- ggplot(data,aes(age,weight)) + geom_line(aes(y=pred3,group=id.f, col=id.f)) + geom_point(aes(age,weight,col=id.f)) + geom_smooth(method=&quot;lm&quot;, se=FALSE, col=&quot;Red&quot;)+ facet_wrap(~girl, labeller = as_labeller(c(&quot;0&quot;=&quot;Boy&quot;,&quot;1&quot;=&quot;Girl&quot;)))+ ggtitle(&quot;Multilevel model (lmodel3)&quot;, subtitle=&quot;Random Intercept and Slope, nonlinear age&quot;) + xlab(&quot;Age (Time)&quot;) + ylab(&quot;Weight&quot;)+ theme(legend.position = &quot;none&quot;) lmodel_int_s2 ## `geom_smooth()` using formula = &#39;y ~ x&#39; \\(~\\) Harder: We have not yet included the birth weight birthw variable in the model. How should we interpret the inclusion of birthw as a fixed effect? What would you expect to happen when you include it? Confirm (or deny) your intuition! Click for solution birthw is an individual level covariate. Hence, it’s inclusion as a fixed effect may help to explain some of the variability in the random intercept terms. I’d expect that adding it in will result in a reduction in the random intercept variance and (probably) an insignificant overall intercept term (since for each individiual, birthw and the random intercept will effectively capture most of the baseline variation.) \\(~\\) End of lab! "],["multilevel-modelling-practical-6-week-7.html", "7 Multilevel Modelling Practical 6 (Week 7) 7.1 Instructions - start here! 7.2 Exercise 1 (Long and wide data shape) 7.3 Exercise 2 (simulation from the two-level longitudinal model) 7.4 End of lab!", " 7 Multilevel Modelling Practical 6 (Week 7) 7.1 Instructions - start here! Exercise 1 considers long and wide data shapes, illustrated by the Oxford boys data set. Exercise 2 involves a simulation exercise (simulating from a two-level longitudinal model). You may also use this lab to work on the formative assignment. Let’s begin by loading the necessary packages and data: require(lme4) require(lmerTest) require(ggplot2) 7.2 Exercise 1 (Long and wide data shape) Let’s return to the Oxboys data, discussed in the lecture, which is a built-in R data set: require(nlme) data(Oxboys) This data set was by default given in long format. But assume we wanted this data in wide format, for instance in order to carry out a multivariate analysis. Let’s have a brief look at the data frame: head(Oxboys) ## Grouped Data: height ~ age | Subject ## Subject age height Occasion ## 1 1 -1.0000 140.5 1 ## 2 1 -0.7479 143.4 2 ## 3 1 -0.4630 144.8 3 ## 4 1 -0.1643 147.1 4 ## 5 1 -0.0027 147.7 5 ## 6 1 0.2466 150.2 6 dim(Oxboys) ## [1] 234 4 We see that there are two variables capturing the “time” component: the age variable the Occasion variable There is a one-to-one relationship between these two variables, so for the purpose of creating a “wide” data frame, we can choose any of these. In this case, we have decided to drop age: Oxboys.wide &lt;- reshape(Oxboys, direction=&quot;wide&quot;, idvar=&quot;Subject&quot;, timevar=&quot;Occasion&quot;, drop=&quot;age&quot;) head(Oxboys.wide) ## Subject height.1 height.2 height.3 height.4 height.5 height.6 height.7 height.8 height.9 ## 1 1 140.5 143.4 144.8 147.10 147.70 150.2 151.7 153.3 155.8 ## 10 2 136.9 139.1 140.1 142.60 143.20 144.0 145.8 146.8 148.3 ## 19 3 150.0 152.1 153.9 155.80 156.00 156.9 157.4 159.1 160.6 ## 28 4 155.7 158.7 160.6 163.30 164.40 167.3 170.7 172.0 174.8 ## 37 5 145.8 147.3 148.7 149.78 150.22 152.5 154.8 156.4 158.7 ## 46 6 142.4 143.8 145.2 146.30 147.10 148.1 148.9 149.1 151.0 We can produce pairwise scatterplots of the data, which gives a sense of the correlation between heights measured at different times: plot(Oxboys.wide[,-1], col=Oxboys.wide$Subject) Let’s re-transform the data back into a long data format: Oxboys.long&lt;- reshape(Oxboys.wide, direction=&quot;long&quot;, idvar=&quot;Subject&quot;, varying=list(2:10),v.names=&quot;height&quot; ) head(Oxboys.long) ## Subject time height ## 1.1 1 1 140.5 ## 2.1 2 1 136.9 ## 3.1 3 1 150.0 ## 4.1 4 1 155.7 ## 5.1 5 1 145.8 ## 6.1 6 1 142.4 TASK: Convince yourself that the Oxboys.long data frame is equivalent to the original Oxboys frame. Check also the help file for reshape and make sure you’re happy with the syntax. 7.2.1 Regression vs multilevel analysis By ignoring group structure, we can fit a regression model of the form \\[y_{ti}=a+b T_{ti}+\\epsilon_{ti}\\] model.lm &lt;- lm(height ~ age, data=Oxboys) Let’s also obtain prediction intervals for each response value: lmpred &lt;- data.frame(predict(model.lm,interval=&quot;prediction&quot;)) lmpred$age &lt;- Oxboys$age lmpred$height &lt;- Oxboys$height lmpred$Subject &lt;- Oxboys$Subject head(lmpred) ## fit lwr upr age height Subject ## 1 142.8508 126.8115 158.8901 -1.0000 140.5 1 ## 2 144.4947 128.4920 160.4975 -0.7479 143.4 1 ## 3 146.3526 130.3788 162.3263 -0.4630 144.8 1 ## 4 148.3004 132.3430 164.2578 -0.1643 147.1 1 ## 5 149.3542 133.3995 165.3088 -0.0027 147.7 1 ## 6 150.9799 135.0212 166.9386 0.2466 150.2 1 We see the fitted value \\(\\hat{y}_{ti} = \\hat{a} +\\hat{b} T_{ti}\\), lower and upper limits of a 95% prediction interval, age, height and the subject label. Let’s plot the prediction interval for subject 2: lmpredS2 &lt;- lmpred[lmpred$Subject==2,] ggplot(lmpredS2,aes(age,height))+ geom_point()+ geom_line(aes(y=fit))+ geom_line(aes(y=lwr))+ geom_line(aes(y=upr)) This doesn’t look terrible, although the fit tracks somewhat above the actual data. TASK: Try generating the above plots for different subjects (in particular, try subjects 1 and 10). Does the prediction interval change? If not, why not? Click for solution The prediction interval does not change. The model ignores group structure and can only explain one source of variation (within individuals) but not the variation between individuals. Consequently, the prediction intervals use the estimated error variance based on the entire data set, irrespective of which individual (subject) we’re looking at. We can see this by plotting the full data set and overlaying the prediction interval: ggplot(lmpred,aes(age,height))+ geom_line(aes(y=fit))+ geom_line(aes(y=lwr))+ geom_line(aes(y=upr))+ geom_point(aes(col=Subject),show.legend=FALSE) \\(~\\) Now, let’s fit a random intercept model of the form \\[y_{ti}=a+u_i + bT_{ti} + \\epsilon_{ti}\\] where the random intercept terms are \\(u_i \\sim N(0,\\sigma^2_u)\\). We use the following code to fit the model: model.lmer &lt;- lmer(height ~ 1+age+(1|Subject),data=Oxboys) To obtain prediction intervals based on the lmer output, we need the following package: require(merTools) Now obtain prediction intervals for each response value and append to the lmpred data frame to give a new data frame pred: lmerpred &lt;- data.frame(predictInterval(model.lmer)) names(lmerpred) &lt;- c(&quot;fit2&quot;,&quot;lwr2&quot;,&quot;upr2&quot;) pred &lt;- cbind(lmerpred,lmpred) head(pred) ## fit2 lwr2 upr2 fit lwr upr age height Subject ## 1 141.6153 144.2665 138.8262 142.8508 126.8115 158.8901 -1.0000 140.5 1 ## 2 143.2855 146.0189 140.5028 144.4947 128.4920 160.4975 -0.7479 143.4 1 ## 3 145.0851 147.7315 142.5478 146.3526 130.3788 162.3263 -0.4630 144.8 1 ## 4 146.9969 149.7938 144.4247 148.3004 132.3430 164.2578 -0.1643 147.1 1 ## 5 148.1749 150.9344 145.4503 149.3542 133.3995 165.3088 -0.0027 147.7 1 ## 6 149.7160 152.5418 147.0057 150.9799 135.0212 166.9386 0.2466 150.2 1 Finally, we can overlay prediction intervals for subject 2: predS2 &lt;- pred[pred$Subject==2,] ggplot(predS2,aes(age,height))+ geom_point()+ geom_line(aes(y=fit))+ geom_line(aes(y=lwr))+ geom_line(aes(y=upr))+ geom_line(aes(y=fit2),col=&quot;red&quot;)+ geom_line(aes(y=lwr2),col=&quot;red&quot;)+ geom_line(aes(y=upr2),col=&quot;red&quot;) The prediction interval based on the random intercept model is much tighter (since the within subjects variation is considerably lower than for the simple linear regression model which ignores group structure). To see this, consider first the summary of the linear regression model: summary(model.lm) ## ## Call: ## lm(formula = height ~ age, data = Oxboys) ## ## Residuals: ## Min 1Q Median 3Q Max ## -21.6570 -5.1403 0.4872 4.7514 18.9430 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 149.3718 0.5286 282.599 &lt; 2e-16 *** ## age 6.5210 0.8170 7.982 6.64e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.081 on 232 degrees of freedom ## Multiple R-squared: 0.2154, Adjusted R-squared: 0.2121 ## F-statistic: 63.71 on 1 and 232 DF, p-value: 6.635e-14 The square of the residual standard error gives an estimate of the residual error variance \\(\\sigma^2\\). Now consider the summary of the random intercept model: summary(model.lmer) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: height ~ 1 + age + (1 | Subject) ## Data: Oxboys ## ## REML criterion at convergence: 940 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.1857 -0.6350 -0.1339 0.6252 2.5357 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Subject (Intercept) 65.555 8.097 ## Residual 1.718 1.311 ## Number of obs: 234, groups: Subject, 26 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 149.3717 1.5902 25.0002 93.93 &lt;2e-16 *** ## age 6.5239 0.1325 207.0000 49.23 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## age -0.002 Look at the random effect variance estimate \\(\\sigma^2_u\\) versus the estimate of residual variance \\(\\sigma^2\\). Most of the variation is between subjects! Hence, after accounting for group structure, the within subjects variation is relatively small. \\(~\\) 7.3 Exercise 2 (simulation from the two-level longitudinal model) Suppose that we want to set up and simulate from a hypothetical model of MATH43515 student stress levels (for 30 students) over a 6 week period with the following variables: stress - response variable on [0,100] with 100 representing max stress. week - time covariate taking values 1 to 6. ML - a binary (upper level) covariate taking the value 1 if a student has taken the Machine Learning module and 0 otherwise. ID - a unique student identifier. Imagine that the model we want to simulate from takes the form \\[y_{ti}=a + u_i + b T_{ti} + v_i T_{ti} + c z_i + \\epsilon_{ti}, \\quad i=1,\\ldots,30, \\quad t=1,\\ldots,6\\] where \\(T_{ti}=t-1\\) represents week number, \\(z_i\\) represents the binary ML variable, \\(u_i \\sim N(0,\\sigma^2_u)\\), \\(v_i \\sim N(0,\\sigma^2_v)\\) and \\(\\epsilon_{ti}\\sim N(0,\\sigma^2)\\). Let’s set up a data frame within which to store the simulated data: set.seed(43515) ID &lt;- rep(seq(1,30),6) ML &lt;- rep(sample(0:1,30,replace=TRUE),6) week &lt;- rep(seq(0,5),each=30) stress &lt;- rep(0,180) #overwrite this later data &lt;- data.frame(ID,stress,week,ML) We will need to pick some parameter values. How about: a &lt;- 40 #baseline stress level b &lt;- 5 #stress increases 5 units with every week c &lt;- 5 #if you&#39;re taking ML, expected stress increases by 5 units! sigu &lt;- 1 # Random intercept standard deviation sigv &lt;- 1 # Random slope standard deviation sig &lt;- 1 #error standard deviation Now simulate from the model. We will do this by looping over time inside a loop over individuals: set.seed(43515) #for reproducibility #Simulate individual random effects ui &lt;- rnorm(30,0,sigu) vi &lt;- rnorm(30,0,sigv) for(t in 1:6) { for(i in 1:30) { #simulate response at each time within individuals data$stress[(t-1)*30+i] &lt;- a+ui[i]+(b+vi[i])*(t-1)+c*data$ML[(t-1)*30+i]+rnorm(1,0,sig) } } head(data) ## ID stress week ML ## 1 1 45.48698 0 1 ## 2 2 38.15454 0 0 ## 3 3 46.78894 0 1 ## 4 4 40.86827 0 0 ## 5 5 44.64929 0 1 ## 6 6 45.55972 0 1 Notice how the random effects only change from individual to individual. Let’s visualise the data we’ve generated: ggplot(data,aes(x=week,y=stress,group=ID,col=ID))+ geom_line()+ facet_wrap(~ML) Fit the model from which the data were simulated and check that the parameter estimates are consistent with the ground truth: model.synth &lt;- lmer(stress ~ 1+week+ML+(1+week|ID),data=data) summary(model.synth) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: stress ~ 1 + week + ML + (1 + week | ID) ## Data: data ## ## REML criterion at convergence: 639.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.50911 -0.59396 0.02096 0.62229 2.45261 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.5436 0.7373 ## week 0.5565 0.7460 0.50 ## Residual 1.0127 1.0063 ## Number of obs: 180, groups: ID, 30 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 39.8509 0.2499 28.3719 159.44 &lt; 2e-16 *** ## week 5.1770 0.1431 29.0001 36.17 &lt; 2e-16 *** ## ML 5.0378 0.3769 28.0001 13.37 1.12e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) week ## week 0.122 ## ML -0.653 0.000 All looks well - the fixed effect estimates and random effect variances are consistent with the ground truth values that generated the data. There are various ways in which you could perform further analysis and check against what you expect to see e.g.  Check to see that the interaction between ML and week is insignificant. Click for solution Add in the cross level interaction as follows: model.synth2 &lt;- lmer(stress ~ 1+week+ML+week:ML+(1+week|ID),data=data) summary(model.synth2) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: stress ~ 1 + week + ML + week:ML + (1 + week | ID) ## Data: data ## ## REML criterion at convergence: 639.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.49292 -0.59874 0.02114 0.62647 2.45536 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.5443 0.7378 ## week 0.5720 0.7563 0.50 ## Residual 1.0127 1.0063 ## Number of obs: 180, groups: ID, 30 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 39.8363 0.2514 27.9998 158.433 &lt; 2e-16 *** ## week 5.1088 0.1925 28.0001 26.542 &lt; 2e-16 *** ## ML 5.0713 0.3820 27.9998 13.277 1.32e-13 *** ## week:ML 0.1573 0.2924 28.0001 0.538 0.595 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) week ML ## week 0.163 ## ML -0.658 -0.107 ## week:ML -0.107 -0.658 0.163 The p-value is well above the 5% threshold indicating insufficient evidence to reject the null hypothesis that the fixed effect for the cross level intereaction is zero. We therefore conclude that this term is not needed. \\(~\\) Check that the random time slope is needed (we know it is!) Click for solution Perform a likelihood ratio test of the null hypothesis \\(H_0: \\sigma_v=0\\) as follows: ranova(model.synth) ## ANOVA-like table for random-effects: Single term deletions ## ## Model: ## stress ~ week + ML + (1 + week | ID) ## npar logLik AIC LRT Df Pr(&gt;Chisq) ## &lt;none&gt; 7 -319.69 653.38 ## week in (1 + week | ID) 5 -387.72 785.43 136.06 2 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We see a very small p-value suggesting strong evidence against the null hypothesis. We conlude that the random slope on week is needed. \\(~\\) Check the residual diagnostics. Click for solution Check residuals versus fitted values and normality of residuals and random effects: plot(model.synth) qqnorm(resid(model.synth)) qqline(resid(model.synth), col = &quot;red&quot;) qqnorm(ranef(model.synth)$ID[,1]) qqline(ranef(model.synth)$ID[,1], col = &quot;red&quot;) qqnorm(ranef(model.synth)$ID[,2]) qqline(ranef(model.synth)$ID[,2], col = &quot;red&quot;) Unsurprisingly (given how the data were generated), the model assumptions look reasonable. \\(~\\) You could also consider adding in an additional covariate at the lower level! If you’ve got this far and have time to spare, feel free to work on the formative assignment. \\(~\\) 7.4 End of lab! "],["multilevel-modelling-practical-7-week-8.html", "8 Multilevel Modelling Practical 7 (Week 8) 8.1 Instructions - start here! 8.2 Exercise 1 (Aids data: Example 2 from lecture 7) 8.3 Exercise 2 (Leukaemia data: Example 3 from lecture 7) 8.4 Exercise 3: Toxoplasmosis data (Binomial logistic regression) 8.5 ## End of lab!", " 8 Multilevel Modelling Practical 7 (Week 8) 8.1 Instructions - start here! Exercise 1 involves the analysis of the data set used in Example 2 of the week 7 lecture. Exercise 2 considers the data set on survival times from Example 3. Exercise 3 involves a logistic regression model for Binomial data. 8.2 Exercise 1 (Aids data: Example 2 from lecture 7) Read in and visualize the data: aids &lt;- read.table(&quot;https://andygolightly.github.io/teaching/MATH43515/aids.asc&quot;, header = TRUE) plot(aids, type=&quot;h&quot;) Let’s first ignore the fact that the data are counts and fit a simple linear regression model of the form \\[y_i = \\beta_0 +\\beta_1 x_i + \\epsilon_{i},\\quad i=1,\\ldots,14\\] where \\(x_i\\) denotes the \\(i\\)th time point. lm1 &lt;- lm(deaths~time, data=aids) plot(aids, type=&quot;h&quot;,ylim=c(-6,50)) lines(aids$time, predict(lm1)) There are multiple issues here, in addition to ignoring the discrete nature of the response variable. \\(~\\) Let’s use the Poisson distribution to model the response. Recall that if \\(Y\\sim Po(\\lambda)\\) then \\(Y\\) takes values \\(0,1,\\ldots,\\) with probabilities \\[f(y)=\\frac{e^{-\\lambda}\\lambda^y}{y!}=\\exp\\{y\\log (\\lambda)-\\lambda-\\log(y!)\\}\\] with the latter in exponential family form. The mean of \\(Y\\) is \\(\\lambda\\). We can check this via simulation: ypois &lt;- rpois(10000,lambda=2) #simulate Po(2) realisations mean(ypois) ## [1] 1.9981 var(ypois) ## [1] 1.964893 (It turns out that the variance is also \\(\\lambda\\). Try changing \\(\\lambda\\) and the number of simulations.) Now, we can identify the natural link function as \\(\\log(\\cdot)\\). Hence, we will fit a GLM with \\(\\log(\\lambda_i)=\\beta_0+\\beta_1 x_i\\). Fit a Poisson GLM and display the model summary: glm1 &lt;- glm(deaths~time, family=poisson(link=log), data=aids) summary(glm1) ## ## Call: ## glm(formula = deaths ~ time, family = poisson(link = log), data = aids) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.33963 0.25119 1.352 0.176 ## time 0.25652 0.02204 11.639 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 207.272 on 13 degrees of freedom ## Residual deviance: 29.654 on 12 degrees of freedom ## AIC: 86.581 ## ## Number of Fisher Scoring iterations: 5 Add the fitted curve (expected number of aids cases as a function of time) to the plot with: plot(aids, type=&quot;h&quot;) lines(aids$time, predict(glm1, type=&quot;response&quot;)) TASK: Reproduce this plot using ggplot. Hint: this will require geom_segment(). Click for solution Reproduce the plot in ggplot: require(ggplot2) aids$pred &lt;- predict(glm1,type=&quot;response&quot;) ggplot(aids,aes(x=time,xend=time,y=0,yend=deaths))+ geom_segment()+ geom_line(aes(x=time,y=pred))+ xlab(&quot;time&quot;)+ ylab(&quot;deaths&quot;) \\(~\\) TASK: What would be the predicted number of deaths in month 15? There are three ways of answering this question: Manually, by implementing \\(\\exp(\\hat{\\beta}_0+\\hat{\\beta}_1\\times 15)\\); Using function predict to obtain \\(\\hat{\\beta}_0+\\hat{\\beta}_1\\times 15\\), but still exponentiating the output; Using function predict with option type=\"response\", also avoiding the manual transformation. Try at least two of these and make sure that results match! Click for solution Calculate the predicted number of deaths in month 15: exp(predict(glm1, newdata=data.frame(time=15))) ## 1 ## 65.85714 # or predict(glm1, newdata=data.frame(time=15), type=&quot;response&quot;) ## 1 ## 65.85714 # or exp(0.3396+0.2565*15) ## [1] 65.8316 \\(~\\) 8.3 Exercise 2 (Leukaemia data: Example 3 from lecture 7) Read in and display the data leu &lt;- read.table(&quot;https://andygolightly.github.io/teaching/MATH43515/leukaemie.asc&quot;, header=TRUE) plot(leu, xlab=&quot;log(# white blood cells)&quot;,ylab=&quot;survival time&quot;) Let’s fit a simple linear regression model of the form \\[y_i = \\beta_0 +\\beta_1 x_i + \\epsilon_{i},\\quad i=1,\\ldots,14\\] where \\(y_i\\) denotes survival time and \\(x_i\\) denotes the \\(i\\)th \\(\\log_{10}\\) white blood cell count. lm2 &lt;- lm(time~wbc, data=leu) plot(leu, xlab=&quot;log(# white blood cells)&quot;,ylab=&quot;survival time&quot;) lines(leu$wbc, predict(lm2)) The model will predict a negative survival time for a \\(\\log_{10}\\) white blood cell count greater than around 5.15. We could fit a model of the form \\[\\log y_i = \\beta_0 +\\beta_1 x_i + \\epsilon_{i},\\quad i=1,\\ldots,14\\] which would circumvent this issue. (In fact, this would be assuming a lognormal model for the response.) However, plotting the log response against the covariate gives: plot(log(leu), xlab=&quot;log(# white blood cells)&quot;,ylab=&quot;log survival time&quot;) for which there is some suggestion of heteroscedasticity of errors about a hypothetical straight line fit. \\(~\\) We will instead model the expected response with a Gamma distribution. Use the following illustrative code to visualize the density function of the Gamma distribution for shape parameters 1, 2, 3, 4 and 5 (and use this to make clear to yourself why this distribution is useful for modelling waiting times). y &lt;- seq(0,50, by=0.1) shape &lt;- c(1,2,3,4,5) rate &lt;- c(1,1,1,1,1) plot(y, dgamma(y, shape[1], rate[1]), type=&quot;l&quot;,xlab=&quot;y&quot;,ylab=&quot;f(y)&quot;) for (j in 2:4) { lines(y, dgamma(y, shape[j], rate[j]), col=j) } If \\(Y\\sim \\text{Gamma}(a,b)\\) for shape and rate parameters \\(a\\) and \\(b\\), the mean (expectation) of \\(Y\\) is \\(\\mu=a/b\\). Let’s consider a GLM with a log link function so that \\(\\log(\\mu_i) = \\beta_0+\\beta_1 x_i\\) where \\(x_i\\) is the \\(i\\)th value of \\(\\log_{10}\\) white blood cell count. TASK: Fit a generalized linear model with time as response, and wbc as predictor. Use a Gamma response distribution and a log link. Save the model as glm2. Click for solution Fit a generalized linear model with time as response, and wbc as predictor. Use a Gamma response distribution and a log link: glm2 &lt;- glm(time ~ wbc, family=Gamma(link=log), data=leu) summary(glm2) ## ## Call: ## glm(formula = time ~ wbc, family = Gamma(link = log), data = leu) ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.4775 1.6034 5.287 9.13e-05 *** ## wbc -1.1093 0.3872 -2.865 0.0118 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for Gamma family taken to be 0.9388638) ## ## Null deviance: 26.282 on 16 degrees of freedom ## Residual deviance: 19.457 on 15 degrees of freedom ## AIC: 173.97 ## ## Number of Fisher Scoring iterations: 8 \\(~\\) Now plot the fitted response as a function of wbc by running the following code: plot(leu, xlab=&quot;log(number of white blood cells)&quot;,ylab=&quot;survival time&quot;) lines(leu$wbc[order(leu$wbc)], predict(glm2, type=&quot;response&quot;)[order(leu$wbc)]) TASK: In the above, why is the use of order necessary? Click for solution Note that the lines function will draw straight lines between x values specified by wbc and y values specified by the corresponding prediction. Without ordering wbc (and the corresponding predictions accordingly), the resulting plot will look rather strange! Try it out! \\(~\\) TASK: recreate the above plot using ggplot. Click for solution Using ggplot: leu$pred &lt;- predict(glm2,type=&quot;response&quot;) ggplot(leu,aes(x=wbc,y=time))+ geom_point()+ geom_line(aes(x=wbc[order(wbc)],y=pred[order(wbc)]))+ xlab(&quot;log(number of white blood cells)&quot;)+ ylab(&quot;survival time&quot;) \\(~\\) TASK: Predict the survival time for a white blood cell count of 160. Click for solution Predict the survival time for a white blood cell count of 160: predict(glm2,newdata=data.frame(wbc=log10(160)), type=&quot;response&quot;) ## 1 ## 416.7432 \\(~\\) HARDER: What does the following code do? (assuming that glm3 contains the fitted model). After spending some time thinking about this, uncover the solution for a bonus plot. out &lt;- predict(glm2,newdata=data.frame(wbc=log10(160)), type=&quot;link&quot;,se.fit=TRUE) c(exp(out$fit-2*out$se.fit),exp(out$fit+2*out$se.fit)) Click for solution The following code produces an approximate 95% confidence interval for the expected survival time given a white blood cell count of 160. out &lt;- predict(glm2,newdata=data.frame(wbc=log10(160)), type=&quot;link&quot;,se.fit=TRUE) c(exp(out$fit-2*out$se.fit),exp(out$fit+2*out$se.fit)) ## 1 1 ## 89.45865 1941.39827 Note that we first find an interval for the linear predictor and then run this through the response function (which is the exp function for this example). Bonus - overlay a 95% confidence interval: out &lt;- predict(glm2, type=&quot;link&quot;,se.fit=TRUE) leu$lower &lt;- exp(out$fit-2*out$se.fit) leu$upper &lt;- exp(out$fit+2*out$se.fit) ggplot(leu,aes(x=wbc,y=time))+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.1)+ geom_point()+ geom_line(aes(x=wbc[order(wbc)],y=pred[order(wbc)]))+ xlab(&quot;log(number of white blood cells)&quot;)+ ylab(&quot;survival time&quot;) \\(~\\) 8.4 Exercise 3: Toxoplasmosis data (Binomial logistic regression) The so-called rainfall or toxoplasmosis data give the number of subjects (Cases) out of (Total) testing positively for toxoplasmosis in each of 34 cities in El Salvador. The covariate Rain is the the annual rainfall in mm. Please load the data and carry out the following operation to create a variable x giving the annual rainfall per 1000mm: require(npmlreg) data(rainfall) rainfall$x &lt;- rainfall$Rain/1000 This is, again, an example for logistic regression. We want to model a probability of “success” (occurence of a binary event; here toxoplasmosis infection) as a function of covariates (here: Rain). However, here the situation is different to the shuttle example. Now the response is not just Bernoulli (failure or non-failure), but Binomial, where we have, for each observation, the number of Cases (\\(y\\)) out of total tests carried out (\\(n\\)). Note that the model is now \\(Y \\sim \\text{Binomial}(n,\\pi)\\), where the observed ratio \\(y/n\\) can be interpreted as an empirical estimate of the probability, \\(\\pi\\), of “success”. The fitting methodology does however not use this ratio directly. One needs to give the full vectors of successes and non-successes, \\(y\\) and \\(n-y\\), to glm, as follows: toxo.glm &lt;- glm(cbind(Cases,Total-Cases) ~ x, family=binomial(link=logit), data=rainfall) summary(toxo.glm) ## ## Call: ## glm(formula = cbind(Cases, Total - Cases) ~ x, family = binomial(link = logit), ## data = rainfall) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.3424 0.8522 0.402 0.688 ## x -0.1562 0.4428 -0.353 0.724 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 74.212 on 33 degrees of freedom ## Residual deviance: 74.087 on 32 degrees of freedom ## AIC: 168.78 ## ## Number of Fisher Scoring iterations: 3 An alternative way of supplying this information is as follows. glm(Cases/Total ~ x, family=binomial(link=logit), weights=Total, data=rainfall) ## ## Call: glm(formula = Cases/Total ~ x, family = binomial(link = logit), ## data = rainfall, weights = Total) ## ## Coefficients: ## (Intercept) x ## 0.3424 -0.1562 ## ## Degrees of Freedom: 33 Total (i.e. Null); 32 Residual ## Null Deviance: 74.21 ## Residual Deviance: 74.09 AIC: 168.8 \\(~\\) TASK: Check whether the model fit improves when including higher powers of x (quadratic, cubic,…). Consider the value of AIC to answer this question. Hint: Functions of variables can be included into the linear predictor using I(.). Click for solution toxo2.glm &lt;- glm(Cases/Total ~ x+I(x^2), family=binomial(link=logit), weights= Total, data=rainfall) toxo2.glm ## ## Call: glm(formula = Cases/Total ~ x + I(x^2), family = binomial(link = logit), ## data = rainfall, weights = Total) ## ## Coefficients: ## (Intercept) x I(x^2) ## 0.308739 -0.121636 -0.008778 ## ## Degrees of Freedom: 33 Total (i.e. Null); 31 Residual ## Null Deviance: 74.21 ## Residual Deviance: 74.09 AIC: 170.8 toxo3.glm &lt;- glm(Cases/Total ~ x+I(x^2)+I(x^3), family=binomial(link=logit), weights= Total, data=rainfall) toxo3.glm ## ## Call: glm(formula = Cases/Total ~ x + I(x^2) + I(x^3), family = binomial(link = logit), ## data = rainfall, weights = Total) ## ## Coefficients: ## (Intercept) x I(x^2) I(x^3) ## -290.17 449.98 -231.13 39.32 ## ## Degrees of Freedom: 33 Total (i.e. Null); 30 Residual ## Null Deviance: 74.21 ## Residual Deviance: 62.63 AIC: 161.3 We see a relatively big drop in AIC for the final model, so let’s go with toxo.glm. \\(~\\) TASK: Using your model settled on just above, predict the ratio of toxoplasmosis infections for a city in El Salvador with annual rainfall of 2000mm. Click for solution predict(toxo3.glm, newdata=data.frame(x=2), type=&quot;response&quot;) ## 1 ## 0.460961 \\(~\\) TASK: Compute the predicted toxoplasmsosis incidence as a function of rainfall. Plot the fitted curve versus rainfall. Click for solution toxo3.predict &lt;- predict(toxo3.glm, type=&quot;response&quot;) rainfall3 &lt;- cbind(rainfall, toxo3.predict) plot(rainfall$x, rainfall$Cases/rainfall$Total, ylab=&quot;Cases/Total&quot;) lines(rainfall$x[order(rainfall$x)], toxo3.predict[order(rainfall$x)]) \\(~\\) TASK: Reproduce the plot using ggplot2. Click for solution ggplot(data = rainfall, aes(x = x, y = Cases/Total)) + geom_point(size=0.7) + geom_line(color=&#39;red&#39;, data = rainfall3, aes(x=x, y=toxo3.predict)) \\(~\\) TASK (harder) Add confidence bands for the fitted curve to the just created plot. Hint: use geom_smooth with method=glm and specify a formula for the model. Click for solution Rather than obtain an interval for the linear predictor before running through the response function, we can use geom_smooth. ggplot(data = rainfall, aes(x = x, y = Cases/Total)) + geom_point(size=0.7) + geom_smooth(method = glm, formula=cbind(rainfall$Cases,rainfall$Total-rainfall$Cases)~ x+I(x^2)+I(x^3), method.args=list(family=&quot;binomial&quot;), se = TRUE, size = .5, alpha = .8) How do you reconcile the relatively narrow bounds with the fact that so many observations lie scattered well outside those bounds? \\(~\\) 8.5 ## End of lab! "],["multilevel-modelling-practical-8-week-9.html", "9 Multilevel Modelling Practical 8 (Week 9) 9.1 Instructions - start here! 9.2 Preliminaries 9.3 Exercise 1: Betablocker data 9.4 Exercise 2 (digging deeper) 9.5 Exercise 3 (optional): Toxoplasmosis data revisited 9.6 Summative assessment 9.7 ## End of lab!", " 9 Multilevel Modelling Practical 8 (Week 9) 9.1 Instructions - start here! Exercise 1 involves the analysis of the Betablocker data set used in last week’s lecture. Exercise 2 digs a little deeper using the same data set. Exercise 3 considers the Toxoplasmosis data from last week’s lab. The remaining time can be used to work on the summative assessment. 9.2 Preliminaries We load the R packages lme4 and ggplot2. require(lme4) # contains glmer require(ggplot2) # for the use of ggplot 9.3 Exercise 1: Betablocker data We will initially reproduce the analysis as demonstrated in the lecture. We read the betablocker data directly from the internet. betablok &lt;- read.table( &#39;https://andygolightly.github.io/teaching/MATH43515/betablok.dat&#39;) head(betablok) ## V1 V2 ## 1 3 39 ## 2 3 38 ## 3 14 116 ## 4 7 114 ## 5 11 93 ## 6 5 69 Add trial and centre information: names(betablok) &lt;- c(&#39;r&#39;,&#39;n&#39;) betablok$treat &lt;- factor(gl(2,1),labels=c(0,1)) betablok$center &lt;- gl(22,2) Let’s take a quick look at data layout: dim(betablok) ## [1] 44 4 head(betablok) ## r n treat center ## 1 3 39 0 1 ## 2 3 38 1 1 ## 3 14 116 0 2 ## 4 7 114 1 2 ## 5 11 93 0 3 ## 6 5 69 1 3 We now consider the GLM fit after ignoring multi-level structure: betablok.glm &lt;- glm(cbind(r,(n-r))~treat,data=betablok,family=binomial) summary(betablok.glm) ## ## Call: ## glm(formula = cbind(r, (n - r)) ~ treat, family = binomial, data = betablok) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.19711 0.03359 -65.417 &lt; 2e-16 *** ## treat1 -0.25737 0.04942 -5.207 1.91e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 332.99 on 43 degrees of freedom ## Residual deviance: 305.76 on 42 degrees of freedom ## AIC: 527.19 ## ## Number of Fisher Scoring iterations: 4 Note the AIC value of 527. Recall that AIC is given by \\(2(p+1)-2\\log\\hat{L}\\) where \\(\\log\\hat{L}\\) is the maximised log-likelihood. When comparing two (potentially non-nested) models, we prefer the model with smaller AIC. \\(~\\) Now account for two-level structure, with center (i.e. hospital) in the upper level: summary(betablok.glmer &lt;- glmer(cbind(r,(n-r))~treat+(1|center), data=betablok, family=binomial)) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [&#39;glmerMod&#39;] ## Family: binomial ( logit ) ## Formula: cbind(r, (n - r)) ~ treat + (1 | center) ## Data: betablok ## ## AIC BIC logLik deviance df.resid ## 324.4 329.8 -159.2 318.4 41 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.8876 -0.5129 0.0605 0.4969 1.8623 ## ## Random effects: ## Groups Name Variance Std.Dev. ## center (Intercept) 0.2362 0.486 ## Number of obs: 44, groups: center, 22 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.19618 0.11292 -19.450 &lt; 2e-16 *** ## treat1 -0.26091 0.04982 -5.237 1.63e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## treat1 -0.205 Note the AIC value of 324. Let’s think about the treatment effect. We have the following model: \\[ Y_{ij} \\sim \\text{Binomial}(n_{ij},\\pi_{ij}) \\] for treatment \\(i\\) in center \\(j\\). Note that \\(\\pi_{ij}\\) is the probability of patient mortality for that treatment-center combination. We further have via the logit link that \\[ \\log\\left(\\frac{\\pi_{ij}}{1-\\pi_{ij}}\\right)=a+u_j+b x_{ij} \\] which gives \\[ \\pi_{ij}= \\frac{e^{a+u_j+b x_{ij}}}{1+e^{a+u_j+b x_{ij}}} \\] where \\(x_{ij}\\) is 0 or 1 for no treatment versus treatment and \\(u_j\\sim N(0,\\sigma^2_u)\\) is the random intercept term. When \\(x_{ij}=0\\) the expected log-odds ratio is \\[ \\hat{a}=-2.2. \\] When \\(x_{ij}=1\\), the expected log-odds ratio is \\[ \\hat{a}+\\hat{b} = -2.2 - 0.26. \\] Hence, the effect of treatment is the change the log-odds ratio by -0.26 and therefore multiplys the odds-ratio (in favour of death) by \\(\\exp(-0.26)=0.77\\). That is, the treatment appears to be effective in reducing probability of patient mortality. This observation has also been made in the literature; e.g. Aitkin et al (2009, Statistical Modelling in R, page 526), note: “The treatment produces a significant, though small, reduction in death risk compared to the control: the odds of death are reduced…”. \\(~\\) We can do a little diagnostc checking by looking at the normality assumption for the random intercept terms: qqnorm(ranef(betablok.glmer)$center[,1]) qqline(ranef(betablok.glmer)$center[,1]) which doesn’t look too bad given the size of the data set. 9.4 Exercise 2 (digging deeper) This is a multi-centre trial, so (in terms of analysis) comparable to a multi-site trial. Hence, a natural extension of the preceding analysis would be the consideration of random slopes. Adapt the model betablok.glmer accordingly so that it allows for centre-specific slopes. summary(betablok.glmer2&lt;-glmer(cbind(r,(n-r))~treat+(treat|center), data=betablok,family=binomial)) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [&#39;glmerMod&#39;] ## Family: binomial ( logit ) ## Formula: cbind(r, (n - r)) ~ treat + (treat | center) ## Data: betablok ## ## AIC BIC logLik deviance df.resid ## 327.7 336.6 -158.8 317.7 39 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.45612 -0.40887 0.02525 0.44137 1.39542 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## center (Intercept) 0.254613 0.5046 ## treat1 0.009585 0.0979 -0.45 ## Number of obs: 44, groups: center, 22 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.20413 0.11749 -18.760 &lt; 2e-16 *** ## treat1 -0.24681 0.05888 -4.192 2.77e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## treat1 -0.364 TASK: Consider AIC. Do the random slopes appear to be worth including? Click for solution The AIC is 327.7, which has increased (from 324.4 for the random intercept model). Hence, it appears that random slopes are not needed. \\(~\\) TASK: Apply the anova function on the pair of models to endorse your judgement. (Note: both models are fitted using maximum likelihood so using anova here is perfectly acceptible. We used ranova to compare models with and without random slopes in the linear mixed effect model setting due to lmer using restricted maximum likelihood to perform the fitting.) Click for solution anova(betablok.glmer, betablok.glmer2) ## Data: betablok ## Models: ## betablok.glmer: cbind(r, (n - r)) ~ treat + (1 | center) ## betablok.glmer2: cbind(r, (n - r)) ~ treat + (treat | center) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## betablok.glmer 3 324.42 329.77 -159.21 318.42 ## betablok.glmer2 5 327.65 336.58 -158.83 317.65 0.7661 2 0.6818 We have insufficient evidence to reject the null hypothesis that the random slope variance is zero. We don’t need the random slopes. \\(~\\) Inspect the random intercept and slope values for betablok.glmer2 (using plot_model): require(sjPlot) plot_model(betablok.glmer2, type=&quot;re&quot;) What can you say about the random treatment slopes? \\(~\\) Let’s do some additional diagnostic checking for the random intercept and slope model. Start with diagnostics for the random effects: qqnorm(ranef(betablok.glmer2)$center[[1]]) #random intercepts qqline(ranef(betablok.glmer2)$center[[1]]) qqnorm(ranef(betablok.glmer2)$center[[2]]) #random slopes qqline(ranef(betablok.glmer2)$center[[2]]) TASK: What is your overall conclusion? Click for solution Including random slopes does not seem worthwhile. This conclusion is supported by AIC, the likelihood ratio test and the plot of the fitted random slope effects (which are very similar, suggesting very small variance). Overall, the combined studies point towards a small reduction of death risk due to the use betablockers. \\(~\\) 9.5 Exercise 3 (optional): Toxoplasmosis data revisited We revisit the Toxoplasmosis (rainfall) data from the previous practical. We load and prepare the data frame as previously. require(npmlreg) data(rainfall) rainfall$x &lt;- rainfall$Rain/1000 We had fitted the following two logistic models, and identified some superiority of the cubic over the linear moodel. toxo.glm &lt;- glm(cbind(Cases,Total-Cases) ~ x, family=binomial(link=logit), data=rainfall) summary(toxo.glm) ## ## Call: ## glm(formula = cbind(Cases, Total - Cases) ~ x, family = binomial(link = logit), ## data = rainfall) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.3424 0.8522 0.402 0.688 ## x -0.1562 0.4428 -0.353 0.724 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 74.212 on 33 degrees of freedom ## Residual deviance: 74.087 on 32 degrees of freedom ## AIC: 168.78 ## ## Number of Fisher Scoring iterations: 3 toxo3.glm &lt;- glm(cbind(Cases,Total-Cases) ~ x+I(x^2)+I(x^3), family=binomial(link=logit), data=rainfall) summary(toxo3.glm) ## ## Call: ## glm(formula = cbind(Cases, Total - Cases) ~ x + I(x^2) + I(x^3), ## family = binomial(link = logit), data = rainfall) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -290.17 87.22 -3.327 0.000878 *** ## x 449.98 134.70 3.341 0.000836 *** ## I(x^2) -231.13 69.03 -3.348 0.000813 *** ## I(x^3) 39.32 11.74 3.351 0.000806 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 74.212 on 33 degrees of freedom ## Residual deviance: 62.635 on 30 degrees of freedom ## AIC: 161.33 ## ## Number of Fisher Scoring iterations: 3 Endorse this result by applying anova onto this pair of models: anova(toxo.glm,toxo3.glm,test=&quot;LRT&quot;) ## Analysis of Deviance Table ## ## Model 1: cbind(Cases, Total - Cases) ~ x ## Model 2: cbind(Cases, Total - Cases) ~ x + I(x^2) + I(x^3) ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 32 74.087 ## 2 30 62.635 2 11.453 0.003259 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 In the previous practical we already expressed some suspicion about the relevance of the cubic term: While statistically significant, is it “really there”, or are we “overfitting” a random feature of this data? In this connection it is worth recalling a basic feature of the Binomial model: It is a one-parameter distribution, with a fixed mean-variance relationship (just as the Poisson model, but unlike the Normal or Gamma model) and with no scale parameter to absorb “excess variability”. If the data possess more inherent variability than this rigid mean-relationship allows, one speaks of “overdispersion”. It turns out that one way of addressing this problem is two consider the data set “artificially” as a two-level model, i.e. to introduce a random effect for the “upper level” which however coincides with the observation index (Aitkin et al, Statistical Modelling in R, page Sec 8.4.3.). That is, each observation gets assigned its own random effect, which then can absorb the excess variation. Create a vector of observation ID’s, rainfall$ID &lt;- 1:34 and then fit an “empty” model only containing the random effect for the IDs, that is (1|D). toxo.glmm3 &lt;- glmer(cbind(Cases,Total-Cases) ~ (1|ID), family=binomial, data=rainfall) summary(toxo.glmm3) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [&#39;glmerMod&#39;] ## Family: binomial ( logit ) ## Formula: cbind(Cases, Total - Cases) ~ (1 | ID) ## Data: rainfall ## ## AIC BIC logLik deviance df.resid ## 154.6 157.7 -75.3 150.6 32 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.26132 -0.82407 -0.04503 0.40309 1.32907 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.2634 0.5132 ## Number of obs: 34, groups: ID, 34 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.1229 0.1381 -0.89 0.374 We see that this model leads to a lower AIC than any of the models considered previously! We conclude that there is no actual dependency of toxoplasmosis rates on rainfall, and that the observed cubic trend has been due to unexplained excess variability (=overdispersion). \\(~\\) 9.6 Summative assessment If there is still time remaining, please use this to work on your summative assessment. 9.7 ## End of lab! "],["multilevel-modelling-practical-9-week-10.html", "10 Multilevel Modelling Practical 9 (Week 10) 10.1 Dealing with missing values", " 10 Multilevel Modelling Practical 9 (Week 10) 10.1 Dealing with missing values Missing values in data are a common phenomenon in real world problems. Knowing how to handle missing values effectively is a required step to reduce bias and to produce powerful models. In this final workshop, we will explore different methods of handling missing data. \\(~\\) 10.1.0.1 Data preparation and pattern We will use the Boston Housing dataset in the mlbench package to discuss the various approaches to treating missing values. Though the original Boston Housing data doesn’t have missing values, we will randomly introduce missing values. This way, we can validate the imputed missing values against the actual observations, so that we know how effective are the approaches in reproducing the actual data. Lets begin by importing the data from the mlbench package and randomly insert missing values (NA). require(mlbench) data (&quot;BostonHousing&quot;, package=&quot;mlbench&quot;) # initialize the data # load the data original &lt;- BostonHousing # backup original data # Introduce missing values set.seed(100) BostonHousing[sample(1:nrow(BostonHousing), 40), &quot;rad&quot;] &lt;- NA BostonHousing[sample(1:nrow(BostonHousing), 40), &quot;ptratio&quot;] &lt;- NA head(BostonHousing) ## crim zn indus chas nox rm age dis rad tax ptratio b lstat medv ## 1 0.00632 18 2.31 0 0.538 6.575 65.2 4.0900 1 296 15.3 396.90 4.98 24.0 ## 2 0.02731 0 7.07 0 0.469 6.421 78.9 4.9671 2 242 17.8 396.90 9.14 21.6 ## 3 0.02729 0 7.07 0 0.469 7.185 61.1 4.9671 2 242 17.8 392.83 4.03 34.7 ## 4 0.03237 0 2.18 0 0.458 6.998 45.8 6.0622 NA 222 18.7 394.63 2.94 33.4 ## 5 0.06905 0 2.18 0 0.458 7.147 54.2 6.0622 3 222 18.7 396.90 5.33 36.2 ## 6 0.02985 0 2.18 0 0.458 6.430 58.7 6.0622 3 222 18.7 394.12 5.21 28.7 The missing values have been inserted in the rad (index of accessibility to radial highways) and ptratio (pupil-teacher ratio by town). Though we know where the missing values are, let’s quickly check the ‘missings’ pattern using md.pattern (a function in mice package). require(mice) md.pattern(BostonHousing) ## crim zn indus chas nox rm age dis tax b lstat medv rad ptratio ## 430 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 ## 36 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 ## 36 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 ## 4 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 ## 0 0 0 0 0 0 0 0 0 0 0 0 40 40 80 # pattern or missing values in data. We see that 36 rows in the data set have a missing value on just ptratio, 36 have a missing value on just rad and 4 rows have both rad and ptratio as missing. \\(~\\) 10.1.0.2 Method 1. Deleting the observations If you have large number of observations in your data set, where all the cases to be predicted are sufficiently well represented in the data, then try deleting (or not to include missing values while model building, for example by setting na.action=na.omit) those observations (rows) that contain missing values. Let’s regress medv on ptratio and rad after deleting the missingness (that is, deleting the rows for which there is at least one missing value), and compare against a model fit that uses the original data set: # Example - regress medv (value of homes) on ptratio and rad model1 &lt;- lm(medv ~ ptratio + rad, data=BostonHousing, na.action=na.omit) #though na.omit is the default in lm() summary(model1) ## ## Call: ## lm(formula = medv ~ ptratio + rad, data = BostonHousing, na.action = na.omit) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18.225 -4.355 -0.964 2.967 33.566 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 57.04649 3.31434 17.212 &lt; 2e-16 *** ## ptratio -1.76906 0.18788 -9.416 &lt; 2e-16 *** ## rad -0.20322 0.04862 -4.180 3.54e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.659 on 427 degrees of freedom ## (76 observations deleted due to missingness) ## Multiple R-squared: 0.2894, Adjusted R-squared: 0.2861 ## F-statistic: 86.94 on 2 and 427 DF, p-value: &lt; 2.2e-16 model2 &lt;- lm(medv ~ ptratio + rad, data=original) summary(model2) ## ## Call: ## lm(formula = medv ~ ptratio + rad, data = original) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18.349 -4.567 -1.177 3.001 33.426 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 57.44986 3.18089 18.061 &lt; 2e-16 *** ## ptratio -1.79043 0.18090 -9.897 &lt; 2e-16 *** ## rad -0.19621 0.04498 -4.362 1.56e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.793 on 503 degrees of freedom ## Multiple R-squared: 0.2849, Adjusted R-squared: 0.2821 ## F-statistic: 100.2 on 2 and 503 DF, p-value: &lt; 2.2e-16 Compare summaries - we see relatively little difference in output. \\(~\\) Let’s dig a little deeper with a synthetic data experiment. We will simulate data from a simple linear regression model, then repeatedly delete a proportion specified by the user, and compare fitted lines. set.seed(43515) sim &lt;-function(prop=0.1,N=50) { x &lt;- runif(100,-10,10) y &lt;- rnorm(100,1+2*x,5) plot(x,y) abline(lm(y~x)) for(i in 1:N) { indices &lt;- sample(1:100,round(100*prop)) ymis &lt;- y[-indices] xmis &lt;- x[-indices] lines(abline(lm(ymis~xmis),col=i)) } } TASK: Make sure you understand what the above function is doing. Execute the function for different values of prop e.g. 0.1, 0.5, 0.9. Is the behaviour as expected? Click for solution #prop=0.1 sim() #prop=0.5 sim(prop=0.5) #prop=0.8 sim(prop=0.9) Unsurprisingly, the lines become more variable as the proportion of missingness increases. Nevertheless, if we were to look at the average intercept and slope values, we’d find that these would be close to the ground truth values. The missingness mechanism is MCAR so we expect increased variance in the parameter estimates but no increase in bias. \\(~\\) 10.1.0.3 2. Imputation with mean / median / mode Replacing the missing values with the mean / median / mode is a crude way of treating missing values. Depending on the context, e.g. if the variation is low or if the variable has low leverage over the response, such a rough approximation is acceptable and could possibly give satisfactory results. Let’s impute using the mean for the Boston Housing data ptratio variable. The following code chunk demonstrates how this can be done without overwriting the BostonHousing data. BostonHousing2 &lt;- BostonHousing #Copy the data to avoid an overwrite BostonHousing2$ptratio[is.na(BostonHousing2$ptratio)] &lt;- mean(BostonHousing2$ptratio, na.rm = TRUE) md.pattern(BostonHousing2) ## crim zn indus chas nox rm age dis tax ptratio b lstat medv rad ## 466 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 ## 40 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 ## 0 0 0 0 0 0 0 0 0 0 0 0 0 40 40 Compute the accuracy: actuals &lt;- original$ptratio[is.na(BostonHousing$ptratio)] predicteds &lt;- rep(mean(BostonHousing$ptratio, na.rm=TRUE), length(actuals)) mae &lt;- mean(abs(actuals - predicteds)) mse &lt;- mean((actuals - predicteds)^2) rmse &lt;- sqrt(mse) smape &lt;- mean(2 * abs(actuals - predicteds) / (abs(actuals) + abs(predicteds)) * 100) list(MAE = mae, MSE = mse, RMSE = rmse, sMAPE = smape) ## $MAE ## [1] 1.70029 ## ## $MSE ## [1] 3.908088 ## ## $RMSE ## [1] 1.976888 ## ## $sMAPE ## [1] 9.348085 Note the RMSE value. We will use benchmark further methods against this. \\(~\\) 10.1.0.4 3. Prediction 10.1.0.5 3.1. kNN Imputation DMwR::knnImputation uses a k-Nearest neighbours approach to impute missing values. kNN imputation in simpler terms is as follows: for every observation to be imputed, it identifies the ‘k’ closest observations based on euclidean distance and computes the weighted average (weighted based on inverse distance) of these ‘k’ observations. The advantage is that you can impute all the missing values in all variables with one call to the function. It takes the whole data frame as the argument and you don’t even have to specify which variable you want to impute. library(DMwR2) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo knnOutput &lt;- knnImputation(BostonHousing) #Don&#39;t include the response. anyNA(knnOutput) ## [1] FALSE Compute the accuracy using just the ptratio variable (to allow comparison with that obtained when using mean imputation). actuals &lt;- original$ptratio[is.na(BostonHousing$ptratio)] predicteds &lt;- knnOutput[is.na(BostonHousing$ptratio), &quot;ptratio&quot;] mse &lt;- mean((actuals - predicteds)^2) rmse &lt;- sqrt(mse) rmse ## [1] 0.9329963 How much has root mean square error (RMSE) improved by? \\(~\\) 10.1.0.6 3.2 mice “mice” is short for “Multivariate Imputation by Chained Equations” and is an R package that provides advanced features for missing value treatment. It uses a slightly uncommon way of implementing the imputation in 2-steps, using mice() to build the model and complete() to generate the completed data. The mice(df) function produces multiple complete copies of the data frame df, each with different imputations of the missing data. The complete() function returns one or several of these data sets, with the default being the first. Let’s see how to impute ptratio. miceMod &lt;- mice(BostonHousing, method=&quot;norm.predict&quot;) # perform mice imputation, based on linear regression. ## ## iter imp variable ## 1 1 rad ptratio ## 1 2 rad ptratio ## 1 3 rad ptratio ## 1 4 rad ptratio ## 1 5 rad ptratio ## 2 1 rad ptratio ## 2 2 rad ptratio ## 2 3 rad ptratio ## 2 4 rad ptratio ## 2 5 rad ptratio ## 3 1 rad ptratio ## 3 2 rad ptratio ## 3 3 rad ptratio ## 3 4 rad ptratio ## 3 5 rad ptratio ## 4 1 rad ptratio ## 4 2 rad ptratio ## 4 3 rad ptratio ## 4 4 rad ptratio ## 4 5 rad ptratio ## 5 1 rad ptratio ## 5 2 rad ptratio ## 5 3 rad ptratio ## 5 4 rad ptratio ## 5 5 rad ptratio miceOutput &lt;- complete(miceMod) # generate the completed data. anyNA(miceOutput) ## [1] FALSE The norm.predict argument uses predicted values from linear regression to impute the missingness. Have a look at the help file for mice to see what other methods are possible. For those that did the Machine Learning module, several will be familiar! Compute the accuracy of ptratio: actuals &lt;- original$ptratio[is.na(BostonHousing$ptratio)] predicteds &lt;- miceOutput[is.na(BostonHousing$ptratio), &quot;ptratio&quot;] mse &lt;- mean((actuals - predicteds)^2) rmse &lt;- sqrt(mse) rmse ## [1] 1.488587 We seem to be doing worse (or at least no better?) than the knn approach (but we’re not really harnessing the full power of the mice package). An additional benefit of mice is that it can also handle factors. The rad variable takes values from \\(\\{1,2,\\ldots,24\\}\\). There may be good reasons for treating it as continuous, but for the purposes of demonstration, let’s treat it as discrete. miceMod &lt;- mice(BostonHousing, method=&quot;cart&quot;) #perform mice imputation, based on classification and regression trees (CART). ## ## iter imp variable ## 1 1 rad ptratio ## 1 2 rad ptratio ## 1 3 rad ptratio ## 1 4 rad ptratio ## 1 5 rad ptratio ## 2 1 rad ptratio ## 2 2 rad ptratio ## 2 3 rad ptratio ## 2 4 rad ptratio ## 2 5 rad ptratio ## 3 1 rad ptratio ## 3 2 rad ptratio ## 3 3 rad ptratio ## 3 4 rad ptratio ## 3 5 rad ptratio ## 4 1 rad ptratio ## 4 2 rad ptratio ## 4 3 rad ptratio ## 4 4 rad ptratio ## 4 5 rad ptratio ## 5 1 rad ptratio ## 5 2 rad ptratio ## 5 3 rad ptratio ## 5 4 rad ptratio ## 5 5 rad ptratio miceOutput &lt;- complete(miceMod) #generate the completed data. anyNA(miceOutput) ## [1] FALSE Now compute the accuracy of rad: actuals &lt;- original$rad[is.na(BostonHousing$rad)] predicteds &lt;- miceOutput[is.na(BostonHousing$rad), &quot;rad&quot;] mean(actuals != predicteds) # compute misclass error. ## [1] 0.175 Note that classification and regression trees (the imputation method used above) is beyond the scope of the course (although several of you will know this from the Machine Learning module). Let’s complete the multiple imputation workflow. We use the with function to fit the regression model to each of the 5 imputed data sets: model3 &lt;- with(miceMod,lm(medv ~ ptratio + rad)) summary(model3) ## # A tibble: 15 × 7 ## term estimate std.error statistic p.value nobs df.residual ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 (Intercept) 56.6 3.15 18.0 4.78e-56 506 503 ## 2 ptratio -1.74 0.179 -9.71 1.53e-20 506 503 ## 3 rad -0.203 0.0449 -4.52 7.70e- 6 506 503 ## 4 (Intercept) 56.9 3.18 17.9 1.04e-55 506 503 ## 5 ptratio -1.75 0.181 -9.72 1.45e-20 506 503 ## 6 rad -0.206 0.0451 -4.57 6.21e- 6 506 503 ## 7 (Intercept) 56.7 3.16 17.9 5.46e-56 506 503 ## 8 ptratio -1.74 0.179 -9.72 1.36e-20 506 503 ## 9 rad -0.203 0.0450 -4.51 8.07e- 6 506 503 ## 10 (Intercept) 56.6 3.16 17.9 9.37e-56 506 503 ## 11 ptratio -1.74 0.180 -9.68 2.02e-20 506 503 ## 12 rad -0.204 0.0451 -4.52 7.84e- 6 506 503 ## 13 (Intercept) 56.5 3.15 17.9 6.15e-56 506 503 ## 14 ptratio -1.73 0.179 -9.68 1.96e-20 506 503 ## 15 rad -0.209 0.0450 -4.63 4.65e- 6 506 503 Finally, use the pool function to pool results: summary(pool(model3)) ## term estimate std.error statistic df p.value ## 1 (Intercept) 56.6434253 3.16571683 17.892764 499.1928 1.103289e-55 ## 2 ptratio -1.7415941 0.17975027 -9.688965 499.4531 1.855954e-20 ## 3 rad -0.2049607 0.04512901 -4.541661 498.7355 7.006823e-06 If you wish, you can compare the results to those obtained using the orginal data set. \\(~\\) 10.1.0.7 References Rubin, D. B. Multiple imputation for nonresponse in surveys. John Wiley &amp; Sons, 1987. Schafer, J.L. (1997). Analysis of Incomplete Multivariate Data. London: Chapman &amp; Hall. Table 6.14. Van Buuren, S. and Groothuis-Oudshoorn, K. (2011). mice: Multivariate Imputation by Chained Equations in R. Journal of Statistical Software, 45(3), 1-67. pdf "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
