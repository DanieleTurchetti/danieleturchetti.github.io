<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 workshop: K-means | Data Exploration, Visualisation and Unsupervised Learning</title>
  <meta name="description" content="Chapter 4 workshop: K-means | Data Exploration, Visualisation and Unsupervised Learning" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 workshop: K-means | Data Exploration, Visualisation and Unsupervised Learning" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 workshop: K-means | Data Exploration, Visualisation and Unsupervised Learning" />
  
  
  

<meta name="author" content="Dr Hyeyoung Maeng" />


<meta name="date" content="2023-02-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="workshop-ca.html"/>
<link rel="next" href="workshop-hierarchical-clustering.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> DEVUL </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Down the rabbit-hole</a></li>
<li class="chapter" data-level="2" data-path="workshop-pca.html"><a href="workshop-pca.html"><i class="fa fa-check"></i><b>2</b> Workshop: PCA</a>
<ul>
<li class="chapter" data-level="2.1" data-path="workshop-pca.html"><a href="workshop-pca.html#iris-data"><i class="fa fa-check"></i><b>2.1</b> Iris data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="workshop-ca.html"><a href="workshop-ca.html"><i class="fa fa-check"></i><b>3</b> workshop: CA</a>
<ul>
<li class="chapter" data-level="3.0.1" data-path="workshop-ca.html"><a href="workshop-ca.html#toothpaste-usage-data"><i class="fa fa-check"></i><b>3.0.1</b> Toothpaste usage data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="workshop-k-means.html"><a href="workshop-k-means.html"><i class="fa fa-check"></i><b>4</b> workshop: K-means</a></li>
<li class="chapter" data-level="5" data-path="workshop-hierarchical-clustering.html"><a href="workshop-hierarchical-clustering.html"><i class="fa fa-check"></i><b>5</b> workshop: Hierarchical clustering</a></li>
<li class="chapter" data-level="6" data-path="workshop-mba.html"><a href="workshop-mba.html"><i class="fa fa-check"></i><b>6</b> workshop: MBA</a>
<ul>
<li class="chapter" data-level="6.0.1" data-path="workshop-mba.html"><a href="workshop-mba.html#tutorial-breadbasket_dms-data"><i class="fa fa-check"></i><b>6.0.1</b> Tutorial: BreadBasket_DMS data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Exploration, Visualisation and Unsupervised Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="workshop-k-means" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> workshop: K-means<a href="workshop-k-means.html#workshop-k-means" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This exercise involves the use of K-means and K-medoids (a robust alternative to K-means). We will understand the algorithm used to program K-means and understand how we can combine PCA with K-means clustering for visualization.
At the end of the workshop, we will also understand why K-medoids is robust to outliers.</p>
<p><br />
</p>
<div id="k-means-iris-data" class="section level4 hasAnchor" number="4.0.0.1">
<h4><span class="header-section-number">4.0.0.1</span> K-means (Iris data):<a href="workshop-k-means.html#k-means-iris-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br />
</p>
<p>We will use the <code>factoextra</code> package for visualization. Recall that iris data set has a natural category for the species (<code>three levels: Setosa, Versicolor, Virginica</code>). We may want to ask how good our clustering is, for example, how does our new clusters compares with the natural grouping of the species.<br />
<br />
</p>
<ol style="list-style-type: lower-roman">
<li>We first scale the data. (Why is this important?)</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="workshop-k-means.html#cb1-1" aria-hidden="true" tabindex="-1"></a>iris.scaled <span class="ot">&lt;-</span> <span class="fu">scale</span>(iris[, <span class="sc">-</span><span class="dv">5</span>])</span></code></pre></div>
<p>We can motivate the number of required clusters by plotting <code>total within-cluster sum of square (wss)</code> versus number of cluster. This can be accomplished using <code>fviz_nbclust()</code> function from the <code>factoextra</code> package</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="workshop-k-means.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="workshop-k-means.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_nbclust</span>(iris.scaled, kmeans, <span class="at">method =</span> <span class="st">&quot;wss&quot;</span>) </span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>This Figure is treated the same way as we did with the <strong>scree plot</strong>. We locate the bend (knee) in the plot. This seems to be at k=3. So we will use three clusters for the analysis.</p>
<p>The model can be fitted as follows:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="workshop-k-means.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute k-means with k = 3</span></span>
<span id="cb4-2"><a href="workshop-k-means.html#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb4-3"><a href="workshop-k-means.html#cb4-3" aria-hidden="true" tabindex="-1"></a>km.res <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(iris.scaled, <span class="dv">3</span>, <span class="at">nstart =</span> <span class="dv">25</span>)</span>
<span id="cb4-4"><a href="workshop-k-means.html#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(km.res)</span></code></pre></div>
<pre><code>## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;     &quot;tot.withinss&quot;
## [6] &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;         &quot;ifault&quot;</code></pre>
<p><br />
</p>
<p>Do you remember what <code>nstart = 25</code> is? It means that R will try 25 different random initial cluster assignments and then select the best results corresponding to the one with the lowest within cluster variation.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="workshop-k-means.html#cb6-1" aria-hidden="true" tabindex="-1"></a>km.res</span></code></pre></div>
<pre><code>## K-means clustering with 3 clusters of sizes 50, 53, 47
## 
## Cluster means:
##   Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1  -1.01119138  0.85041372   -1.3006301  -1.2507035
## 2  -0.05005221 -0.88042696    0.3465767   0.2805873
## 3   1.13217737  0.08812645    0.9928284   1.0141287
## 
## Clustering vector:
##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
##  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2
##  [75] 2 3 3 3 2 2 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3
## [112] 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 3 3 3 3 3 3 2 2 3 3 3 2 3 3 3 2 3 3 3 2 3
## [149] 3 2
## 
## Within cluster sum of squares by cluster:
## [1] 47.35062 44.08754 47.45019
##  (between_SS / total_SS =  76.7 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;     &quot;tot.withinss&quot;
## [6] &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;         &quot;ifault&quot;</code></pre>
<p>The total variability explained by the three clusters is 76.7 %</p>
<p><br />
</p>
<p>We can find the means of the four variables based on the newly created clusters (check the link on the function <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/aggregate">aggregate</a> for more details). This can be used to evaluate the performance of the clusters that we obtained via K-means relative to the true class labels?
<em>We can use the <code>table()</code> function in R to compare the true class labels to the class labels obtained by clustering.</em></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="workshop-k-means.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aggregate</span>(iris[,<span class="sc">-</span><span class="dv">5</span>], <span class="at">by=</span><span class="fu">list</span>(<span class="at">cluster=</span>km.res<span class="sc">$</span>cluster), mean)</span></code></pre></div>
<pre><code>##   cluster Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1       1     5.006000    3.428000     1.462000    0.246000
## 2       2     5.801887    2.673585     4.369811    1.413208
## 3       3     6.780851    3.095745     5.510638    1.972340</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="workshop-k-means.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compare K-means clustering to the true class labels</span></span>
<span id="cb10-2"><a href="workshop-k-means.html#cb10-2" aria-hidden="true" tabindex="-1"></a>dd <span class="ot">&lt;-</span> <span class="fu">cbind</span>(iris, <span class="at">cluster =</span> km.res<span class="sc">$</span>cluster)</span>
<span id="cb10-3"><a href="workshop-k-means.html#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(dd<span class="sc">$</span>Species,dd<span class="sc">$</span>cluster)</span></code></pre></div>
<pre><code>##             
##               1  2  3
##   setosa     50  0  0
##   versicolor  0 39 11
##   virginica   0 14 36</code></pre>
<p>Setosa from our clustering completely agree with the original label of the species. All the 50 observations are correctly clustered. Out of the 50 observations from Versicolor, 39 agrees with the label while 11 observations are labeled as Virginca. 36 observations from Virginca are put in the correct cluster. Overall, 83.3% correct classification is obtained from the algorithm (((50+39+36)/150)*100).</p>
<p><br />
</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="workshop-k-means.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize kmeans clustering</span></span>
<span id="cb12-2"><a href="workshop-k-means.html#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(km.res, iris[, <span class="sc">-</span><span class="dv">5</span>], <span class="at">ellipse.type =</span> <span class="st">&quot;norm&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br />
(ii) Recall that in Workshop 1 (PCA), we used the function <code>fviz_pca_biplot()</code> to display PCA plot in two dimensions. The idea is that PCA is first performed on the data and K-means clustering is carried out on the first two principal component score vectors. Let’s do this with iris data and use <code>fviz_cluster</code> function to plot the resulting clusters</p>
<p><br />
</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="workshop-k-means.html#cb13-1" aria-hidden="true" tabindex="-1"></a>pr.out <span class="ot">=</span> <span class="fu">prcomp</span>(iris.scaled ) </span>
<span id="cb13-2"><a href="workshop-k-means.html#cb13-2" aria-hidden="true" tabindex="-1"></a>labels <span class="ot">&lt;-</span> dd<span class="sc">$</span>Species</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="workshop-k-means.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( pr.out<span class="sc">$</span>x[,<span class="dv">1</span>], pr.out<span class="sc">$</span>x[,<span class="dv">2</span>], <span class="at">col=</span>labels, <span class="at">pch=</span><span class="dv">19</span>, <span class="at">xlab =</span> <span class="st">&quot;PC1&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC2&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" />
Two components are retained as we did in PCA of iris data.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="workshop-k-means.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb15-2"><a href="workshop-k-means.html#cb15-2" aria-hidden="true" tabindex="-1"></a>kmean.out <span class="ot">=</span> <span class="fu">kmeans</span>( pr.out<span class="sc">$</span>x[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)], <span class="at">centers=</span><span class="dv">3</span>, <span class="at">nstart=</span><span class="dv">25</span>)</span>
<span id="cb15-3"><a href="workshop-k-means.html#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(kmean.out, pr.out<span class="sc">$</span>x[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)], </span>
<span id="cb15-4"><a href="workshop-k-means.html#cb15-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">ellipse.type =</span> <span class="st">&quot;norm&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;PC1 (73%)&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC2 (22.9%)&quot;</span> )</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-10-1.png" width="576" style="display: block; margin: auto;" /></p>
<p><br />
</p>
<p><br />
</p>
</div>
<div id="k-medoids-iris-data" class="section level4 hasAnchor" number="4.0.0.2">
<h4><span class="header-section-number">4.0.0.2</span> K-medoids (Iris data):<a href="workshop-k-means.html#k-medoids-iris-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br />
</p>
<p>K-medoids algorithm is a clustering approach related to K-means clustering for partitioning a data set into k clusters. In K-medoids clustering, each cluster is represented by one of the data point in the cluster. These points are named cluster <code>medoids</code>. Medoid corresponds to the most centrally located point in the cluster. While K-means takes the average (centroid) of the <span class="math inline">\(k^\text{th}\)</span> cluster to minimize the total within cluster variation, K-medoids replaces this by an optimization step which restricts the search
space to the observations within the <span class="math inline">\(k^\text{th}\)</span> cluster.</p>
<p>The main advantage of K-medoids over K-means clustering is that it is less sensitive to outliers (Can you think of why?). The most common K-medoids clustering methods is the PAM algorithm (Partitioning Around Medoids). We will use a faster implementation of PAM using the <code>CLARA (Clustering Large Applications)</code> function within <code>cluster</code> package in this workshop.
Other packages for K-medoids in R are <code>kmedoids()</code> function in <em>clue package (Cluster Ensembles)</em> and <code>pamk()</code> in <em>fpc package</em>.</p>
<p>The model is fitted as:</p>
<p><code>clara(x, k, metric="euclidean" stand=FALSE)</code>,</p>
<p>where:</p>
<ul>
<li><p>x: data matrix or dissimilarity matrix</p></li>
<li><p>k: number of clusters</p></li>
<li><p>metric: <code>euclidean</code> and <code>manhattan</code> distance</p></li>
<li><p>stand: if set to TRUE, the variables are scaled to have unit variance before the analysis takes place.</p></li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="workshop-k-means.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb16-2"><a href="workshop-k-means.html#cb16-2" aria-hidden="true" tabindex="-1"></a>iris.scaled <span class="ot">&lt;-</span> <span class="fu">scale</span>(iris[, <span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb16-3"><a href="workshop-k-means.html#cb16-3" aria-hidden="true" tabindex="-1"></a>pam.res <span class="ot">&lt;-</span> <span class="fu">clara</span>(iris.scaled, <span class="at">k=</span><span class="dv">3</span>)</span>
<span id="cb16-4"><a href="workshop-k-means.html#cb16-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb16-5"><a href="workshop-k-means.html#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(pam.res)</span></code></pre></div>
<pre><code>##  [1] &quot;sample&quot;     &quot;medoids&quot;    &quot;i.med&quot;      &quot;clustering&quot; &quot;objective&quot; 
##  [6] &quot;clusinfo&quot;   &quot;diss&quot;       &quot;call&quot;       &quot;silinfo&quot;    &quot;data&quot;</code></pre>
<p>We are more interested in <code>medoids</code> which shows the objects representing cluster than e.g. <code>i.med</code> which gives the ID of the three observations used as the center (remember we do not use centroid here) and <code>clustering</code> which gives a vector containing the cluster number of each object.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="workshop-k-means.html#cb18-1" aria-hidden="true" tabindex="-1"></a>pam.res<span class="sc">$</span>medoids</span></code></pre></div>
<pre><code>##      Sepal.Length Sepal.Width Petal.Length   Petal.Width
## [1,]  -0.89767388   0.7861738  -1.27910398 -1.3110521482
## [2,]  -0.05233076  -0.8198233   0.08043967  0.0008746178
## [3,]   0.79301235  -0.1315388   0.81685914  1.0504160307</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="workshop-k-means.html#cb20-1" aria-hidden="true" tabindex="-1"></a>pam.res<span class="sc">$</span>i.med</span></code></pre></div>
<pre><code>## [1]  40  83 148</code></pre>
<p>Observe that the observations IDs are the 40, 83 and 148 from the scaled iris data corresponds to the medoids shown above. You can easily check this as <code>iris.scaled[c(40,83,148),]</code></p>
<p>The cluster for the observations can be obtained as:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="workshop-k-means.html#cb22-1" aria-hidden="true" tabindex="-1"></a>pam.res<span class="sc">$</span>clustering</span></code></pre></div>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
##  [38] 1 1 1 1 2 1 1 1 1 1 1 1 1 3 3 3 2 3 2 3 2 3 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2
##  [75] 2 3 3 3 2 2 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 2 3 3 3 3
## [112] 3 3 2 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3
## [149] 3 3</code></pre>
<p>As a small task, use the <code>table()</code> function in R to compare the true class labels to the class labels obtained by K-medoids clustering. Does this result offer any improvement over the K-means results obtained in the previous workshop?<br />
</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="workshop-k-means.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(iris<span class="sc">$</span>Species, pam.res<span class="sc">$</span>clustering)</span></code></pre></div>
<pre><code>##             
##               1  2  3
##   setosa     49  1  0
##   versicolor  0 37 13
##   virginica   0  4 46</code></pre>
<p>If you obtained the correct answer, you will notice that Setosa from our clustering method misclassify 1 of the setosa specie as versicolar (49 out of 50 correctly classified). Virginca species got some improvement over the previous K-means results, only 4 observations are misclassified whereas 14 observations are misclasified in K-means. Overall, 88% ((49+37+46)/150*100) correct classification is obtained under K-medoids whereas 83.3% correct classification was obtained for K-means.</p>
<p><br />
We can use the <code>fviz_cluster</code> function to visualize the clusters as before.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="workshop-k-means.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb26-2"><a href="workshop-k-means.html#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(pam.res, iris[, <span class="sc">-</span><span class="dv">5</span>], <span class="at">ellipse.type =</span> <span class="st">&quot;norm&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We show in the figure below that the medoids are indeed a data point whereas centroids are not.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br />
</p>
</div>
<div id="silhouette-measure" class="section level4 hasAnchor" number="4.0.0.3">
<h4><span class="header-section-number">4.0.0.3</span> Silhouette measure<a href="workshop-k-means.html#silhouette-measure" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br />
</p>
<p>Her we use the silhouette measure to determine optimal number of clusters for the USArrests dataset using the following three algorithms: K-means, K-medoids and Hierarchical clustering (with appropriate linkage). Here we use USArrests data set to apply the silhouette measure.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="workshop-k-means.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mclust)</span></code></pre></div>
<pre><code>## Package &#39;mclust&#39; version 6.0.0
## Type &#39;citation(&quot;mclust&quot;)&#39; for citing this R package in publications.</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="workshop-k-means.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;USArrests&quot;</span>)</span>
<span id="cb29-2"><a href="workshop-k-means.html#cb29-2" aria-hidden="true" tabindex="-1"></a>datUS <span class="ot">&lt;-</span> <span class="fu">scale</span>(USArrests)</span></code></pre></div>
<p><br />
</p>
<p>For each algorithm we will compute the overall average silhouette width of each number of clusters. The maximum of these values is the optimal number of cluster.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-19-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-21-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br />
</p>
<p>We used the Silhouette measure to select optimal number of clusters within a method (e.g. K-means). We can select the optimal number of cluster and algorithm using a general validation method implemented in the package. Read more about the <em>clValid</em> package <a href="https://www.jstatsoft.org/article/view/v025i04"></a>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="workshop-ca.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="workshop-hierarchical-clustering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/hmaeng/devul23/edit/master/03-workshopKMEANS.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/hmaeng/devul23/blob/master/03-workshopKMEANS.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
