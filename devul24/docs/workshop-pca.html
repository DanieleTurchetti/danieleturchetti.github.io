<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Workshop: PCA | Data Exploration, Visualisation and Unsupervised Learning</title>
  <meta name="description" content="Chapter 2 Workshop: PCA | Data Exploration, Visualisation and Unsupervised Learning" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Workshop: PCA | Data Exploration, Visualisation and Unsupervised Learning" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Workshop: PCA | Data Exploration, Visualisation and Unsupervised Learning" />
  
  
  

<meta name="author" content="Dr Hyeyoung Maeng" />


<meta name="date" content="2023-02-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="the-pool-of-tears-hello.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> DEVUL </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Down the rabbit-hole</a></li>
<li class="chapter" data-level="2" data-path="workshop-pca.html"><a href="workshop-pca.html"><i class="fa fa-check"></i><b>2</b> Workshop: PCA</a>
<ul>
<li class="chapter" data-level="2.1" data-path="workshop-pca.html"><a href="workshop-pca.html#iris-data"><i class="fa fa-check"></i><b>2.1</b> Iris data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-pool-of-tears-hello.html"><a href="the-pool-of-tears-hello.html"><i class="fa fa-check"></i><b>3</b> The pool of tears Hello</a></li>
<li class="chapter" data-level="4" data-path="a-caucus-race-and-a-long-tale.html"><a href="a-caucus-race-and-a-long-tale.html"><i class="fa fa-check"></i><b>4</b> A caucus-race and a long tale</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Exploration, Visualisation and Unsupervised Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="workshop-pca" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Workshop: PCA<a href="workshop-pca.html#workshop-pca" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>There are two commands for performing principal component analysis (PCA) in R:
<em>princomp()</em> and <em>prcomp()</em> (see details in the
lecture note). The main goal of PCA in the tasks today will be dimensionality reduction. We wish to produce a
smaller set of uncorrelated variables from the larger set of correlated variables. The resulting variables are uncorrelated and can be used as input to other statistical procedures, e.g. principal component regression (PCR).</p>
<p><br />
</p>
<div id="iris-data" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Iris data<a href="workshop-pca.html#iris-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us consider the popular Iris data set (the data set is on Blackboard in a csv file iris.csv). You can also get the data in R by typing <code>data(iris)</code> in the console. The data consists of 5 variables:</p>
<ul>
<li>Species (with three levels: Setosa, Versicolor, Virginica)</li>
<li>Petal length (in mm)</li>
<li>Petal width (in mm)</li>
<li>Sepal length (in mm)</li>
<li>Sepal width (in mm)</li>
</ul>
<p>1 This part involves the use of <code>spectral decomposition</code> to obtain principal components and make appropriate plots (this is the method implemented in <em>princomp()</em> function).</p>
<p>[(i)] Read the data into R and print out the first six rows of the data.</p>
<details>
<summary>
Click for solution
</summary>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="workshop-pca.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span></code></pre></div>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa
## 4          4.6         3.1          1.5         0.2  setosa
## 5          5.0         3.6          1.4         0.2  setosa
## 6          5.4         3.9          1.7         0.4  setosa</code></pre>
</details>
<p>Look at the summary statistics using:</p>
<p><code>summary(iris[,-5])</code> # fifth column in the data is removed</p>
<p>What can you say about the variables in the data set? We can plot a scatter plot matrix using <code>pairs.panels</code> function from <em>psych</em> package:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="workshop-pca.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb3-2"><a href="workshop-pca.html#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs.panels</span>(iris[,<span class="sc">-</span><span class="dv">5</span>],</span>
<span id="cb3-3"><a href="workshop-pca.html#cb3-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">method =</span> <span class="st">&quot;pearson&quot;</span>, <span class="co"># correlation method</span></span>
<span id="cb3-4"><a href="workshop-pca.html#cb3-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">hist.col =</span> <span class="st">&quot;#00AFBB&quot;</span>,</span>
<span id="cb3-5"><a href="workshop-pca.html#cb3-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">density =</span> <span class="cn">TRUE</span>,  <span class="co"># show density plots</span></span>
<span id="cb3-6"><a href="workshop-pca.html#cb3-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">ellipses =</span> <span class="cn">TRUE</span> <span class="co"># show correlation ellipses</span></span>
<span id="cb3-7"><a href="workshop-pca.html#cb3-7" aria-hidden="true" tabindex="-1"></a>             )</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>What can you say about the plot? Do the variables share sufficient information to warrant redundancy?</p>
<p>You can see that the Petal variables are highly correlated (correlation =0.96). They are also highly correlated with the Sepal length variable. This implies that the three variables share redundant information and the use of PCA can remove this redundancy, thereby reducing the dimension of the data.</p>
<p><br />
</p>
<p>[(ii)] Do we need to use Covariance matrix (<span class="math inline">\(\Sigma\)</span>) or Correlation matrix (scale the data)? We can check this by assessing the standard deviation of the variables.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="workshop-pca.html#cb4-1" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="fu">apply</span>(iris[,<span class="sc">-</span><span class="dv">5</span>], <span class="dv">2</span>, sd)</span>
<span id="cb4-2"><a href="workshop-pca.html#cb4-2" aria-hidden="true" tabindex="-1"></a>sd</span></code></pre></div>
<pre><code>## Sepal.Length  Sepal.Width Petal.Length  Petal.Width 
##    0.8280661    0.4358663    1.7652982    0.7622377</code></pre>
<p>The variables should be scaled/correlation matrix used.</p>
<p><br />
</p>
<p>Spectral decomposition can be obtained using the <code>eigen()</code> function</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="workshop-pca.html#cb6-1" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="fu">cor</span>(iris[,<span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb6-2"><a href="workshop-pca.html#cb6-2" aria-hidden="true" tabindex="-1"></a>eigdec <span class="ot">&lt;-</span> <span class="fu">eigen</span>(S)</span>
<span id="cb6-3"><a href="workshop-pca.html#cb6-3" aria-hidden="true" tabindex="-1"></a>eigdec</span></code></pre></div>
<pre><code>## eigen() decomposition
## $values
## [1] 2.91849782 0.91403047 0.14675688 0.02071484
## 
## $vectors
##            [,1]        [,2]       [,3]       [,4]
## [1,]  0.5210659 -0.37741762  0.7195664  0.2612863
## [2,] -0.2693474 -0.92329566 -0.2443818 -0.1235096
## [3,]  0.5804131 -0.02449161 -0.1421264 -0.8014492
## [4,]  0.5648565 -0.06694199 -0.6342727  0.5235971</code></pre>
<p><br />
</p>
<p>The <em>values</em> and <em>vectors</em> from the decomposition are the variances and the principal component loadings respectively.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="workshop-pca.html#cb8-1" aria-hidden="true" tabindex="-1"></a>eig <span class="ot">&lt;-</span>  eigdec<span class="sc">$</span>values</span>
<span id="cb8-2"><a href="workshop-pca.html#cb8-2" aria-hidden="true" tabindex="-1"></a>eig</span></code></pre></div>
<pre><code>## [1] 2.91849782 0.91403047 0.14675688 0.02071484</code></pre>
<p style="color:red">
<strong>Question:</strong> Why is the sum of these eigenvalues 4?
<p>
<p style="color:red">
<strong>Answer:</strong> We have four variables which are now scaled. The variance of each of them is 1. The total variance of all of them is therefore 4.
<p>
<p><br />
</p>
<p>The eigenvectors can be obtained as</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="workshop-pca.html#cb10-1" aria-hidden="true" tabindex="-1"></a>pc_loading <span class="ot">&lt;-</span>  eigdec<span class="sc">$</span>vectors</span>
<span id="cb10-2"><a href="workshop-pca.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(pc_loading) <span class="ot">&lt;-</span> <span class="fu">colnames</span>(iris[,<span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb10-3"><a href="workshop-pca.html#cb10-3" aria-hidden="true" tabindex="-1"></a>pc_loading</span></code></pre></div>
<pre><code>##                    [,1]        [,2]       [,3]       [,4]
## Sepal.Length  0.5210659 -0.37741762  0.7195664  0.2612863
## Sepal.Width  -0.2693474 -0.92329566 -0.2443818 -0.1235096
## Petal.Length  0.5804131 -0.02449161 -0.1421264 -0.8014492
## Petal.Width   0.5648565 -0.06694199 -0.6342727  0.5235971</code></pre>
<p><br />
</p>
<p>We can obtain the proportion of variance explained as follows:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="workshop-pca.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Variances in percentage</span></span>
<span id="cb12-2"><a href="workshop-pca.html#cb12-2" aria-hidden="true" tabindex="-1"></a>eig <span class="ot">&lt;-</span>  eigdec<span class="sc">$</span>values</span>
<span id="cb12-3"><a href="workshop-pca.html#cb12-3" aria-hidden="true" tabindex="-1"></a>variance <span class="ot">&lt;-</span> eig<span class="sc">*</span><span class="dv">100</span><span class="sc">/</span><span class="fu">sum</span>(eig)</span>
<span id="cb12-4"><a href="workshop-pca.html#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Cumulative variances</span></span>
<span id="cb12-5"><a href="workshop-pca.html#cb12-5" aria-hidden="true" tabindex="-1"></a>cumvar <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(variance)</span>
<span id="cb12-6"><a href="workshop-pca.html#cb12-6" aria-hidden="true" tabindex="-1"></a>eig2<span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">eig =</span> eig, <span class="at">variance =</span> variance,</span>
<span id="cb12-7"><a href="workshop-pca.html#cb12-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">cumvariance =</span> cumvar)</span>
<span id="cb12-8"><a href="workshop-pca.html#cb12-8" aria-hidden="true" tabindex="-1"></a>eig2 </span></code></pre></div>
<pre><code>##          eig   variance cumvariance
## 1 2.91849782 72.9624454    72.96245
## 2 0.91403047 22.8507618    95.81321
## 3 0.14675688  3.6689219    99.48213
## 4 0.02071484  0.5178709   100.00000</code></pre>
<p><br />
</p>
<p>We can supplement this result with a scree plot to decide the number of dimensions to keep.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="workshop-pca.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(eig2[, <span class="dv">2</span>], <span class="at">names.arg=</span><span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(eig2),</span>
<span id="cb14-2"><a href="workshop-pca.html#cb14-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">main =</span> <span class="st">&quot;Scree plot&quot;</span>,</span>
<span id="cb14-3"><a href="workshop-pca.html#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab =</span> <span class="st">&quot;Dimensions&quot;</span>,</span>
<span id="cb14-4"><a href="workshop-pca.html#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">&quot;Percentage of variances&quot;</span>,</span>
<span id="cb14-5"><a href="workshop-pca.html#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span><span class="st">&quot;steelblue&quot;</span>)</span>
<span id="cb14-6"><a href="workshop-pca.html#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Add connected line segments to the plot</span></span>
<span id="cb14-7"><a href="workshop-pca.html#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(eig2), eig2[, <span class="dv">2</span>],</span>
<span id="cb14-8"><a href="workshop-pca.html#cb14-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">pch=</span><span class="dv">19</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-8-1.png" width="384" style="display: block; margin: auto;" /></p>
<p style="color:red">
Based on these (both the proportion of variance explained and the scree plot), how many dimensions should be kept for the Iris data set? The answer is that we have two dimensions that cumulatively explain about 96% of the variability in the data. This value is well beyond the rule of thumb which suggested retaining components that explain 80-90% of the variability in the original data set.
<p>
<p><br />
</p>
<p>[(iii)]
Recall that we distinguished between PCA loadings and PCA scores in the lecture. We can derive the pc scores using the following codes:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="workshop-pca.html#cb15-1" aria-hidden="true" tabindex="-1"></a>pc_score <span class="ot">=</span> <span class="fu">as.matrix</span>(<span class="fu">scale</span>(iris[,<span class="sc">-</span><span class="dv">5</span>]))<span class="sc">%*%</span> pc_loading</span>
<span id="cb15-2"><a href="workshop-pca.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(pc_score) <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;PC&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>)</span>
<span id="cb15-3"><a href="workshop-pca.html#cb15-3" aria-hidden="true" tabindex="-1"></a>pc_score[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,]</span></code></pre></div>
<pre><code>##            PC1        PC2        PC3         PC4
## [1,] -2.257141 -0.4784238  0.1272796  0.02408751
## [2,] -2.074013  0.6718827  0.2338255  0.10266284
## [3,] -2.356335  0.3407664 -0.0440539  0.02828231
## [4,] -2.291707  0.5953999 -0.0909853 -0.06573534</code></pre>
<p><br />
</p>
<p>We can now make a scatter plot matrix as before using pc_score as input.</p>
<p>Here’s the plot:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="workshop-pca.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb17-2"><a href="workshop-pca.html#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs.panels</span>(pc_score,</span>
<span id="cb17-3"><a href="workshop-pca.html#cb17-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">method =</span> <span class="st">&quot;pearson&quot;</span>, <span class="co"># correlation method</span></span>
<span id="cb17-4"><a href="workshop-pca.html#cb17-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">hist.col =</span> <span class="st">&quot;#00AFBB&quot;</span>,</span>
<span id="cb17-5"><a href="workshop-pca.html#cb17-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">density =</span> <span class="cn">TRUE</span>,  <span class="co"># show density plots</span></span>
<span id="cb17-6"><a href="workshop-pca.html#cb17-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">ellipses =</span> <span class="cn">TRUE</span> <span class="co"># show correlation ellipses</span></span>
<span id="cb17-7"><a href="workshop-pca.html#cb17-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>The correlation between the PCs (which are the new coordinates) are essential zero as required.</p>
<p><br />
</p>
<p>From now on, we will keep the first two components. We can use the following codes to plot the scores:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="workshop-pca.html#cb18-1" aria-hidden="true" tabindex="-1"></a>pc_score2 <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(pc_score[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>])</span>
<span id="cb18-2"><a href="workshop-pca.html#cb18-2" aria-hidden="true" tabindex="-1"></a>pc_score2<span class="sc">$</span>Species <span class="ot">&lt;-</span> iris<span class="sc">$</span>Species</span>
<span id="cb18-3"><a href="workshop-pca.html#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(pc_score2) <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">150</span>)</span>
<span id="cb18-4"><a href="workshop-pca.html#cb18-4" aria-hidden="true" tabindex="-1"></a>xlim <span class="ot">&lt;-</span> <span class="fu">range</span>(pc_score2[,<span class="dv">1</span>])<span class="sc">*</span><span class="fl">1.1</span></span>
<span id="cb18-5"><a href="workshop-pca.html#cb18-5" aria-hidden="true" tabindex="-1"></a>ylim <span class="ot">&lt;-</span> <span class="fu">range</span>(pc_score2[,<span class="dv">2</span>])<span class="sc">*</span><span class="fl">1.1</span></span>
<span id="cb18-6"><a href="workshop-pca.html#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="workshop-pca.html#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pc_score2[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="at">pch=</span><span class="dv">19</span>, <span class="at">xlim =</span> xlim, <span class="at">ylim=</span>ylim, <span class="at">main =</span> <span class="st">&quot;Plot of PC scores&quot;</span>,</span>
<span id="cb18-8"><a href="workshop-pca.html#cb18-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;red&quot;</span>,<span class="st">&quot;green&quot;</span>)[pc_score2<span class="sc">$</span>Species])</span>
<span id="cb18-9"><a href="workshop-pca.html#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(pc_score2[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="at">labels =</span><span class="fu">rownames</span>(pc_score2[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]),</span>
<span id="cb18-10"><a href="workshop-pca.html#cb18-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">pos =</span> <span class="dv">3</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;red&quot;</span>,<span class="st">&quot;green&quot;</span>)[pc_score2<span class="sc">$</span>Species])</span>
<span id="cb18-11"><a href="workshop-pca.html#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">0</span>, <span class="at">h=</span><span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-11-1.png" width="576" style="display: block; margin: auto;" /></p>
<p><strong>Question: Can you deduce the relationship between the scores and the PCs?</strong></p>
<p style="color:red">
Clearly the two species (on the right) look more similar than the other on the left. The data looks linearly separable (we can draw straight lines and separate the three species).
<p>
<p><br />
</p>
<p>We can also plot the PC loadings:</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-12-1.png" width="576" style="display: block; margin: auto;" /></p>
<p><br />
</p>
<p>As you probably observed, it is not straightforward to explain the plots separately. A biplot displays both the principal component scores and the principal component loadings. Click the link on <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/biplot">biplot</a> to read more. We can now make this plot and explain our observation.</p>
<p><br />
</p>
<p><em>pc_loading2 &lt;- pc_loading[,1:2]</em></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="workshop-pca.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(pc_score2[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],pc_loading2, <span class="at">xlab=</span><span class="st">&quot;PC1 (73%)&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC2 (22.9%)&quot;</span>)</span>
<span id="cb19-2"><a href="workshop-pca.html#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">0</span>, <span class="at">h=</span><span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>From the plot as well as from the factor loadings, first loading vector places approximately equal weight on Sepal length, Petal length and Petal width, with much less weight in Sepal width. The second loading vector places most of its weight on Sepal width. Overall, we see that Sepal length, Petal length and Petal width are located close to each other.</p>
<p><br />
</p>
<p>[(iv)] The correlation between the original variables and the selected PCs is given by</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="workshop-pca.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(iris[,<span class="sc">-</span><span class="dv">5</span>], pc_score[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>])</span></code></pre></div>
<pre><code>##                     PC1         PC2
## Sepal.Length  0.8901688 -0.36082989
## Sepal.Width  -0.4601427 -0.88271627
## Petal.Length  0.9915552 -0.02341519
## Petal.Width   0.9649790 -0.06399985</code></pre>
<p>The output indicates that Sepal length, Petal length and Petal width are highly correlated with PC1 while Sepal width is highly correlated with PC2.</p>
<p><br />
</p>
<p>The quality of representation of the variables is called the squared cosine (cos2) or the squared correlations.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="workshop-pca.html#cb22-1" aria-hidden="true" tabindex="-1"></a>cos2 <span class="ot">&lt;-</span>  (<span class="fu">cor</span>(iris[,<span class="sc">-</span><span class="dv">5</span>], pc_score[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb22-2"><a href="workshop-pca.html#cb22-2" aria-hidden="true" tabindex="-1"></a>cos2</span></code></pre></div>
<pre><code>##                    PC1         PC2
## Sepal.Length 0.7924004 0.130198208
## Sepal.Width  0.2117313 0.779188012
## Petal.Length 0.9831817 0.000548271
## Petal.Width  0.9311844 0.004095980</code></pre>
<p><br />
</p>
<p>The contribution of a variable to a given principal component is (in percentage) : (cos2 * 100) / (total cos2 of the component)</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="workshop-pca.html#cb24-1" aria-hidden="true" tabindex="-1"></a>comp.cos2 <span class="ot">&lt;-</span> <span class="fu">apply</span>(cos2, <span class="dv">2</span>, sum)</span>
<span id="cb24-2"><a href="workshop-pca.html#cb24-2" aria-hidden="true" tabindex="-1"></a>contrib2 <span class="ot">&lt;-</span> <span class="cf">function</span>(cos2, comp.cos2){cos2<span class="sc">*</span><span class="dv">100</span><span class="sc">/</span>comp.cos2}</span>
<span id="cb24-3"><a href="workshop-pca.html#cb24-3" aria-hidden="true" tabindex="-1"></a>contrib <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">apply</span>(cos2,<span class="dv">1</span>, contrib2, comp.cos2))</span>
<span id="cb24-4"><a href="workshop-pca.html#cb24-4" aria-hidden="true" tabindex="-1"></a>contrib</span></code></pre></div>
<pre><code>##                    PC1         PC2
## Sepal.Length 27.150969 14.24440565
## Sepal.Width   7.254804 85.24748749
## Petal.Length 33.687936  0.05998389
## Petal.Width  31.906291  0.44812296</code></pre>
<p><br />
</p>
<p>The contribution can be displayed with a barplot:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="workshop-pca.html#cb26-1" aria-hidden="true" tabindex="-1"></a>names1 <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>,<span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Sepal.Width&quot;</span>)</span>
<span id="cb26-2"><a href="workshop-pca.html#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(contrib[<span class="fu">order</span>(contrib[, <span class="dv">1</span>],<span class="at">decreasing =</span> T),<span class="dv">1</span>], <span class="at">names.arg=</span>names1, </span>
<span id="cb26-3"><a href="workshop-pca.html#cb26-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">main =</span> <span class="st">&quot;Contribution of variables to PC1&quot;</span>,</span>
<span id="cb26-4"><a href="workshop-pca.html#cb26-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab =</span> <span class="st">&quot; &quot;</span>,</span>
<span id="cb26-5"><a href="workshop-pca.html#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">&quot;Percentage of variances&quot;</span>,</span>
<span id="cb26-6"><a href="workshop-pca.html#cb26-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span><span class="st">&quot;steelblue&quot;</span>,<span class="at">las=</span><span class="dv">2</span>,<span class="at">cex.names=</span><span class="fl">0.7</span>)</span>
<span id="cb26-7"><a href="workshop-pca.html#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">25</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lty=</span><span class="dv">3</span>, <span class="at">lwd =</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-17-1.png" width="576" style="display: block; margin: auto;" />
<em>Think about how the codes for barplot above can be modified to show the contribution of variables to PC2.</em></p>
<p><br />
</p>
<p>Notice that the horizontal red line is placed at 25. This is because we have 4 variables and 100/4 = 25. Any variable whose height is up to 25 and above is considered to have contributed significantly to the component.</p>
<p>Observe that the interpretation of cor, cos2 and contrib are similar.</p>
<p><br />
</p>
<p>In fact, the step-by-step process we have followed using various functions is what was packaged in the <code>princomp</code> function for principal component analysis, and it is based on <code>spectral</code> decomposition.</p>
<p><br />
</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-pool-of-tears-hello.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/hmaeng/devul23/edit/master/01-Workshop.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/hmaeng/devul23/blob/master/01-Workshop.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
